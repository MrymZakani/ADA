{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are we consuming more local?\n",
    "\n",
    "## Research questions\n",
    "\n",
    "1. Where are the products we consume in our everyday life coming from?\n",
    "\n",
    "    - Which countries produce the primary resources (ground ingredients) consumed in Switzerland?\n",
    "    - Which countries manufacture most of the products consumed in Switzerland?\n",
    "\n",
    "\n",
    "2. Is there a trend over time to consume more local products?\n",
    "\n",
    "    - Are new products mostly using primary resources from Switzerland? Or from other countries inside Europe?\n",
    "    - Are new products mostly manufactured in Switzerland? Or from other countries inside Europe?\n",
    "    - Is there a trend over time to local products to promote their origin?\n",
    "\n",
    "## Datasets\n",
    "\n",
    "Open Food Facts (https://world.openfoodfacts.org/data)\n",
    "\n",
    "Additional datasets “Evolution de la consommation de denrées alimentaires en Suisse” (https://opendata.swiss/fr/dataset/entwicklung-des-nahrungsmittelverbrauches-in-der-schweiz-je-kopf-und-jahr1) and “Dépenses fédérales pour l’agriculture et l’alimentation” (https://opendata.swiss/fr/dataset/bundesausgaben-fur-die-landwirtschaft-und-die-ernahrung1) from https://opendata.swiss/fr/group/agriculture\n",
    "\n",
    "A last additional dataset for the second question of the project\n",
    "https://www.gate.ezv.admin.ch/swissimpex/public/bereiche/waren/result.xhtml\n",
    "Total of imports of agriculture, forestry and fishing goods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import min\n",
    "from pyspark.sql.functions import to_date, last_day,date_add\n",
    "from datetime import timedelta\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "openfood_file = \"/en.openfoodfacts.org.products.csv\"\n",
    "cities_file = \"/worldcitiespop.csv\"\n",
    "countries_file = \"/GEODATASOURCE-COUNTRY.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- origins: string (nullable = true)\n",
      " |-- manufacturing_places: string (nullable = true)\n",
      " |-- countries: string (nullable = true)\n",
      " |-- origins_tags: string (nullable = true)\n",
      " |-- manufacturing_places_tags: string (nullable = true)\n",
      " |-- countries_tags: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_main = spark.read.csv(DATA_FOLDER+ openfood_file, header=True, mode=\"DROPMALFORMED\", sep = '\\t')\n",
    "\n",
    "dataset_main.createOrReplaceTempView(\"data_main\")\n",
    "\n",
    "# Filter required columns\n",
    "p_id_col = \" code, \"\n",
    "general_cols = \" brands, brands_tags, categories, categories_tags, origins, origins_tags, manufacturing_places, manufacturing_places_tags,labels,labels_tags,emb_codes,emb_codes_tags,first_packaging_code_geo,cities,cities_tags,purchase_places,stores,countries,countries_tags \"\n",
    "geo_cols = \" origins, manufacturing_places, countries \"\n",
    "geo_tags_cols = \" origins_tags, manufacturing_places_tags, countries_tags \"\n",
    "\n",
    "off_df = spark.sql(\"SELECT\" + p_id_col + geo_cols + \",\" + geo_tags_cols + \" FROM data_main\")\n",
    "off_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data Size:\n",
      "7(columns) * 693829(rows)\n"
     ]
    }
   ],
   "source": [
    "off_all_size = off_df.count()\n",
    "off_cols_size = len(off_df.columns)\n",
    "print(\"All data Size:\\n\" + str(off_cols_size) + \"(columns) * \" + str(off_all_size) + \"(rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------------------+---------+------------+-------------------------+--------------+\n",
      "|code|origins|manufacturing_places|countries|origins_tags|manufacturing_places_tags|countries_tags|\n",
      "+----+-------+--------------------+---------+------------+-------------------------+--------------+\n",
      "|   0| 651635|              626848|      561|      651689|                   626868|           561|\n",
      "+----+-------+--------------------+---------+------------+-------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find number of missing data\n",
    "\n",
    "off_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in off_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full GEO information data Size:\n",
      "7(columns) * 26953(rows)\n"
     ]
    }
   ],
   "source": [
    "off_df.createOrReplaceTempView(\"off_df\")\n",
    "\n",
    "sql_filter = \"SELECT * FROM off_df WHERE countries is not NULL \\\n",
    "              AND countries_tags is not NULL \\\n",
    "             AND origins is not NULL AND origins_tags is not NULL AND\\\n",
    "             manufacturing_places is not NULL AND manufacturing_places_tags is not NULL \"\n",
    "\n",
    "off_p_df = spark.sql(sql_filter)\n",
    "off_p_all_size = off_p_df.count()\n",
    "off_p_cols_size = len(off_p_df.columns)\n",
    "print(\"Full GEO information data Size:\\n\" + str(off_p_cols_size) + \"(columns) * \" + str(off_p_all_size) + \"(rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_p_df.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since columns with _tag label have more consistent data, we will use these columns from now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_p_df = off_p_df.drop('countries').drop('manufacturing_places').drop('origins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_p_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode data\n",
    "\n",
    "countries_df = off_p_df.withColumn('origins_tags', F.explode_outer(F.split('origins_tags', ',')))\\\n",
    ".withColumn('manufacturing_places_tags', F.explode_outer(F.split('manufacturing_places_tags', ',')))\\\n",
    ".withColumn('countries_tags', F.explode_outer(F.split('countries_tags', ',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"en:\" occurances before name of each country in coutries_tags\n",
    "countries_df = countries_df.withColumn('countries_tags', F.regexp_replace('countries_tags', \"en:\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------------------+--------------+\n",
      "|         code|origins_tags|manufacturing_places_tags|countries_tags|\n",
      "+-------------+------------+-------------------------+--------------+\n",
      "|0000000274722|      france|                   france|        france|\n",
      "|0000000290616|      quebec|          brossard-quebec|        canada|\n",
      "|0000000394710|      quebec|          brossard-quebec|        canada|\n",
      "|0000001071894|      france|           united-kingdom|united-kingdom|\n",
      "|0000001938067|      quebec|          brossard-quebec|        canada|\n",
      "|0000004302544|      quebec|                 brossard|        canada|\n",
      "|0000004302544|      quebec|                   quebec|        canada|\n",
      "|0000008237798|      quebec|                 brossard|        canada|\n",
      "|0000008237798|      quebec|                   quebec|        canada|\n",
      "|0000008240095|      quebec|          brossard-quebec|        canada|\n",
      "+-------------+------------+-------------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add each row of three columns as new entry in this database as index\n",
    "# Remove repetative words\n",
    "# Map each row to two columns: \"cleaned country name\" and \"is european\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_mapping = countries_df.toPandas()\n",
    "countries_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new database mapping each country to some labels\n",
    "\n",
    "countries_mapping['all_countries'] = countries_mapping.origins_tags + \",\" + countries_mapping.manufacturing_places_tags +\",\" + countries_mapping.manufacturing_places_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.concat([pd.Series(row['all_countries'].split(','))              \n",
    "                    for _, row in countries_mapping.iterrows()]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8469\n"
     ]
    }
   ],
   "source": [
    "countries = countries.drop_duplicates().reset_index(drop=True)\n",
    "countries = countries.str.replace(\"-\", \" \") \n",
    "\n",
    "# Remove numbers from name of countries\n",
    "countries = countries.str.replace('\\d+', '')\n",
    "\n",
    "print(len(countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             france\n",
       "1             quebec\n",
       "2    brossard quebec\n",
       "3     united kingdom\n",
       "4           brossard\n",
       "dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using country name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An external database was used for country names. This database maps each country with country code\n",
    "https://www.geodatasource.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC_FIPS</th>\n",
       "      <th>CC_ISO</th>\n",
       "      <th>TLD</th>\n",
       "      <th>COUNTRY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>AW</td>\n",
       "      <td>.aw</td>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AC</td>\n",
       "      <td>AG</td>\n",
       "      <td>.ag</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE</td>\n",
       "      <td>AE</td>\n",
       "      <td>.ae</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF</td>\n",
       "      <td>AF</td>\n",
       "      <td>.af</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AG</td>\n",
       "      <td>DZ</td>\n",
       "      <td>.dz</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CC_FIPS CC_ISO  TLD          COUNTRY_NAME\n",
       "0      AA     AW  .aw                 Aruba\n",
       "1      AC     AG  .ag   Antigua and Barbuda\n",
       "2      AE     AE  .ae  United Arab Emirates\n",
       "3      AF     AF  .af           Afghanistan\n",
       "4      AG     DZ  .dz               Algeria"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_countries = pd.read_csv(DATA_FOLDER+ countries_file,sep='\\t', error_bad_lines=False)\n",
    "dataset_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_country(data, country_code):\n",
    "    global map_countries\n",
    "    map_countries = map_countries.append({'input': data, 'country_code': country_code}, ignore_index=True)\n",
    "\n",
    "def find_country(data):\n",
    "    output = dataset_countries[dataset_countries.COUNTRY_NAME.str.contains(data, case=False)]\n",
    "    if len(output):\n",
    "        return output.iloc[0].CC_FIPS\n",
    "    return 0\n",
    "\n",
    "def assign_country_code(row):\n",
    "    output = find_country(row)\n",
    "    if output:\n",
    "        map_country(row, output)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_countries = pd.DataFrame(columns=['input', 'country_code'])\n",
    "\n",
    "for i in range(len(countries)):\n",
    "    if assign_country_code(countries[i]):\n",
    "        countries = countries.drop([i])\n",
    "        i -=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "195 name of countries detected in uncleaned dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using City names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An external database was used for city names. This database maps each city with country code\n",
    "\n",
    "https://www.maxmind.com/en/free-world-cities-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad</td>\n",
       "      <td>aixas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ad</td>\n",
       "      <td>aixirivali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ad</td>\n",
       "      <td>aixirivall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad</td>\n",
       "      <td>aixirvall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad</td>\n",
       "      <td>aixovall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country        City\n",
       "0      ad       aixas\n",
       "1      ad  aixirivali\n",
       "2      ad  aixirivall\n",
       "3      ad   aixirvall\n",
       "4      ad    aixovall"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find name of cities and replace with country code (Here some bias may happen, some cities have similar name)\n",
    "\n",
    "dataset_cities = pd.read_csv(DATA_FOLDER+ cities_file,sep=',', error_bad_lines=False, encoding = \"utf-8\")\n",
    "dataset_cities = dataset_cities[['Country', 'City']]\n",
    "dataset_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_city(data):\n",
    "    output = dataset_cities[dataset_cities.City.str.contains(data, case=False, na=False)]\n",
    "    if len(output):\n",
    "        return output.iloc[0].Country\n",
    "    return 0\n",
    "\n",
    "def assign_country_code_using_city(row):\n",
    "    output = find_city(row)\n",
    "    if output:\n",
    "        map_country(row, output)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900\n"
     ]
    }
   ],
   "source": [
    "# Try to map more locations using city names\n",
    "countries = countries.reset_index(drop=True)\n",
    "for i in range(seen,2000):\n",
    "    if assign_country_code_using_city(countries[i]):\n",
    "        countries = countries.drop([i])\n",
    "        i -=1\n",
    "        seen = i\n",
    "print(seen)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2319 locations were matched with city names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the country detection algorithm by manual checking of a sample of 100 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using country name (contain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for index, row in dataset_countries.iterrows():\n",
    "    output = countries[countries.str.contains(row.COUNTRY_NAME, case=False, na=False)]\n",
    "    for i in range(len(output)):\n",
    "        map_country(output.iloc[i], row.CC_FIPS)\n",
    "        countries = countries.drop(countries[countries == output.iloc[i]].index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "629 locations were matched with city names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using City name (contain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(dataset_cities)):\n",
    "    output = countries[countries.str.contains(str(dataset_cities.iloc[j].City) + \" \", case=False, na=False)]\n",
    "    for i in range(len(output)):\n",
    "        map_country(output.iloc[i], dataset_cities.iloc[j].Country)\n",
    "        countries = countries.drop(countries[countries == output.iloc[i]].index[0])\n",
    "        \n",
    "    output = countries[countries.str.contains(\" \" + str(dataset_cities.iloc[j].City), case=False, na=False)]\n",
    "    for i in range(len(output)):\n",
    "        map_country(output.iloc[i], dataset_cities.iloc[j].Country)\n",
    "        countries = countries.drop(countries[countries == output.iloc[i]].index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5,326 name of countries contain name of one city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318 strings remained\n",
      "7151 strings mapped to a country\n"
     ]
    }
   ],
   "source": [
    "print(\"{0} strings remained\\n{1} strings mapped to a country\".format(len(countries), len(map_countries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mapping of countries and remained countries\n",
    "countries.to_csv('output/remained_countries_.csv')\n",
    "map_countries.to_csv('output/mapping_countries_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_countries = pd.read_csv(\"cleaning_data/origins_cleaning.csv\")\n",
    "\n",
    "# Flatten origins column\n",
    "origins_p = non_swiss_sold.withColumn('origins', F.explode_outer(F.split('origins', ',')))\n",
    "\n",
    "# Clean origins countries\n",
    "for index, row in cleaned_countries.iterrows():\n",
    "    if(str(row['replace_with']) != \"nan\"):\n",
    "        origins_p = origins_p.withColumn('origins', F.regexp_replace('origins', \"^\" + row['origins'] + \"$\", row['replace_with']))\n",
    "    else:\n",
    "        origins_p = origins_p.withColumn('origins', F.regexp_replace('origins', row['origins'], \"Not Specified\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dominant importers of ingredients\n",
    "\n",
    "origins_p.createOrReplaceTempView(\"origins_p\")\n",
    "target_origins = spark.sql(\"SELECT origins, COUNT(origins) FROM origins_p GROUP BY origins ORDER BY COUNT(origins) DESC\")\n",
    "target_origins = target_origins.withColumnRenamed('count(origins)' , 'Count')\n",
    "\n",
    "print(\"Number of ingredient importers:\\n\" + str(target_origins.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_origins.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 10 most important countries and number of occurances in ingredients.\n",
    "origin_countries = target_origins.toPandas() \n",
    "origin_countries = origin_countries.head(10)\n",
    "\n",
    "# Plot the number of products imported by 10 most important countries\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(zorder=-1)\n",
    "plt.bar(origin_countries.origins, origin_countries.Count, zorder=3, color='skyblue')\n",
    "plt.ylabel('Number of products')   \n",
    "plt.xticks(origin_countries.origins, rotation='80')\n",
    "plt.title('Fig. The number of products which ingredients are from the 10 most frequent countries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export origins to CSV \n",
    "target_origins.select(\"origins\").toPandas().to_csv('output/origins.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we found the most important countries in case of producing ingredients for products which are imported to Switzerland, We should take the same approach to find the most important manufacturers of this products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten manufacturing_places column\n",
    "manufacturers_p = non_swiss_sold.withColumn('manufacturing_places', F.explode_outer(F.split('manufacturing_places', ',')))\n",
    "\n",
    "# Clean manufacturers countries\n",
    "for index, row in cleaned_countries.iterrows():\n",
    "    if(str(row['replace_with']) != \"nan\"):\n",
    "        manufacturers_p = manufacturers_p.withColumn('manufacturing_places', F.regexp_replace('manufacturing_places', \"^\" + row['origins'] + \"$\", row['replace_with']))\n",
    "    else:\n",
    "        manufacturers_p = manufacturers_p.withColumn('manufacturing_places', F.regexp_replace('manufacturing_places', row['origins'], \"Not Specified\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dominant importers (manufacturers)\n",
    "\n",
    "manufacturers_p.createOrReplaceTempView(\"manufacturers_p\")\n",
    "target_manufacturers = spark.sql(\"SELECT manufacturing_places, COUNT(manufacturing_places) FROM manufacturers_p GROUP BY manufacturing_places ORDER BY COUNT(manufacturing_places) DESC\")\n",
    "target_manufacturers = target_manufacturers.withColumnRenamed('count(manufacturing_places)' , 'Count')\n",
    "# target_manufacturers.show()\n",
    "\n",
    "print(\"Number of Manufacturers:\\n\" + str(target_manufacturers.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 10 most important manufacturers countries and number of occurances.\n",
    "manufacturer_countries = target_manufacturers.toPandas() \n",
    "manufacturer_countries = manufacturer_countries.head(10)\n",
    "\n",
    "# Plot the number of products manufactured by 10 most important countries\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(zorder=-1)\n",
    "plt.bar(manufacturer_countries.manufacturing_places, manufacturer_countries.Count, zorder=3, color='skyblue')\n",
    "plt.ylabel('Number of products')   \n",
    "plt.xticks(manufacturer_countries.manufacturing_places, rotation='80')\n",
    "plt.title('Fig. The number of products manufactured by 10 most important countries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export manufacturing_places to CSV \n",
    "target_manufacturers.select(\"manufacturing_places\").toPandas().to_csv('output/manufacturing_places.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with products' categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to find which countries import what products?\n",
    "In order to answer to this question, first we extract categories corresponding to the products sold in Switzerland but not manufactured in this country. Then we will combine the information provided for manufacturing places of these products with corresponding category. \n",
    "\n",
    "In the end we will extract the 5 most important importers of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_info_df = ' categories '\n",
    "categories_df = spark.sql(\"SELECT\" + p_id_col + extra_info_df + \" FROM data_main\")\n",
    "categories_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in traces_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join table of categories with table of target products (Sold in Switzerland but not manufactured in it)\n",
    "non_swiss_sold.createOrReplaceTempView(\"target_products_df\")\n",
    "categories_df.createOrReplaceTempView(\"categories_df\")\n",
    "joined_df = spark.sql(\"SELECT p.code, c.categories, p.origins, p.manufacturing_places, p.countries  FROM target_products_df p INNER JOIN categories_df c ON p.code = c.code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in joined_df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to above table, just 15 products do not have category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.createOrReplaceTempView(\"target_products_cats\")\n",
    "sql_filter = \"SELECT * FROM target_products_cats WHERE categories is not NULL\"\n",
    "target_products_categories_p = spark.sql(sql_filter)\n",
    "\n",
    "print(\"Number of Products sold in Switzerland with categories:\\n\" + str(target_products_categories_p.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_products_categories_p.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten categories column\n",
    "target_products_categories_p = target_products_categories_p.withColumn('categories', F.explode_outer(F.split('categories', ',')))\n",
    "\n",
    "# Remove occurances of en: in name of categories\n",
    "target_products_categories_p = target_products_categories_p.withColumn('categories', F.regexp_replace('categories', 'en:', ''))\n",
    "\n",
    "target_products_categories_p.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dominant categories\n",
    "target_products_categories_p.createOrReplaceTempView(\"target_products_categories_p\")\n",
    "target_categories = spark.sql(\"SELECT categories, COUNT(categories) FROM target_products_categories_p GROUP BY categories ORDER BY COUNT(categories) DESC\")\n",
    "target_categories = target_categories.withColumnRenamed('count(categories)' , 'Count')\n",
    "target_categories.show()\n",
    "\n",
    "print(\"Number of Categories:\\n\" + str(target_categories.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to above table not all categories are independant and they may contain similar products. We did not change categories for this milestone but we would like to merge some categories in future to have better distinction between countries which import these products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Categories to CSV \n",
    "target_categories.toPandas().to_csv('output/categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 15 most frequent categories and number of occurances.\n",
    "categories = target_categories.toPandas() \n",
    "categories = categories.head(15)\n",
    "\n",
    "# Plot the most frequent categories\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(zorder=-1)\n",
    "plt.barh(categories.categories, categories.Count, zorder=3, color='skyblue')\n",
    "plt.xlabel('Number of products')   \n",
    "plt.title('Fig. The number of products sold in Switzerland')\n",
    "ax.invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_countries = pd.read_csv(\"cleaning_data/origins_cleaning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the most important manufacturer countries for 15 most frequent categories\n",
    "\n",
    "categories_countires_p = target_products_categories_p.withColumn('manufacturing_places', F.explode_outer(F.split('manufacturing_places', ',')))\n",
    "\n",
    "# Clean manufacturers countries\n",
    "for index, row in cleaned_countries.iterrows():\n",
    "    if(str(row['replace_with']) != \"nan\"):\n",
    "        categories_countires_p = categories_countires_p.withColumn('manufacturing_places', F.regexp_replace('manufacturing_places', \"^\" + row['origins'] + \"$\", row['replace_with']))\n",
    "    else:\n",
    "        categories_countires_p = categories_countires_p.withColumn('manufacturing_places', F.regexp_replace('manufacturing_places', row['origins'], \"Not Specified\"))\n",
    "\n",
    "categories_countires_p = categories_countires_p.withColumn('categories', F.explode_outer(F.split('categories', ',')))\n",
    "products_cats_df = categories_countires_p.toPandas()\n",
    "\n",
    "countries_cats = []\n",
    "cat = \"Snacks sucrés\"\n",
    "for index, row in categories.iterrows():\n",
    "    temp_df = products_cats_df[(products_cats_df.categories == row.categories)].groupby('manufacturing_places').count().sort_values(by=['code'], ascending=False).head(5)\n",
    "    countries_cats.append(temp_df)\n",
    "\n",
    "# Each element of countries_cats is a dataframe containing the most important manufacturers\n",
    "# of the corresponding category\n",
    "\n",
    "i = 0\n",
    "print(\"category: \" + str(categories.iloc[i].categories))\n",
    "print(\"The most important manufacturers:\")\n",
    "print(countries_cats[0].head(3).index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use extracted information about the most important manufacturer countries for 15 most frequent categories for our visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openfood = pd.read_csv(DATA_FOLDER + openfood_file, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodSwitzerland = openfood[openfood['countries_tags']==\"en:switzerland\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbProdSwit = len(foodSwitzerland)\n",
    "print(\"Number of products: \", nbProdSwit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first perspective: Compare old vs new products inside the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A product in the dataset is considered \"old\" if its description was uploaded to the dataset before February 2017. By the contrary, it is considered as \"new\" if its description was uploaded after that date.\n",
    "\n",
    "_As that definition is a little rigid, in order to get closer to the real situation, the following assumption is made: From the total products uploaded to the dataset after February 2017, 20% are old products._  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first perspective to tackle the research question, is to compare how in this more than 6 years of existance of the dataset, the characteristics of the products have changed. Specifically, we would like to know if there have been some changes in the origin of the primary resources, or in the origin of the manufacture or in the labels of the products.\n",
    "\n",
    "The study of the evolution in time of each one of those features, will include an __exploratory data analysis__.\n",
    "Finally, a study including the three features will be done, aiming to find an aggregated differentiated behavior in time, reflected in different clusters of periods of time. For that the __K-modes algorithm__ will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Date of first upload: \", min(foodSwitzerland['created_datetime']))\n",
    "print(\"Date of last upload retrieved: \", max(foodSwitzerland['created_datetime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodSwitzerland['created_datetime'] = pd.to_datetime(foodSwitzerland['created_datetime'])\n",
    "foodSwitzerland = foodSwitzerland.sort_values(by='created_datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uploads of products sold in Switzerland, behaves differently in time. Taking into account the histogram presented below, two periods of time are defined:\n",
    "- Period 1: Created for studying the behaviour from \"old\" products. Products uploaded before Feb 2017.\n",
    "- Period 2: Created for studying the behaviour from \"new\" products. Products uploaded after Feb 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateOldInNew = 0.2\n",
    "old_products = len(foodSwitzerland[foodSwitzerland['created_datetime']<\"2017-03-01 00:00:00\"])\n",
    "print(\"Old products: \", old_products + (len(foodSwitzerland)-old_products)*(rateOldInNew))\n",
    "print(\"New products: \", (len(foodSwitzerland)-old_products)*(1-rateOldInNew))\n",
    "foodSwitzerland['created_datetime'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making subdivision of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ch = '[Ss]witzerland|[Ss]uisse|[Ss]chweiz|[Ss]vizerra'\n",
    "filter_local = '[Ss]witzerland|[Ss]uisse|[Ss]chweiz|[Ss]vizerra|[Ll]ocal'\n",
    "\n",
    "place = pd.Series(['Other country','Switzerland', 'No information'], index=[0,1,2])\n",
    "refLabel = pd.Series(['Other Label','Related with Switzerland', 'No information'], index=[0,1,2]) \n",
    "\n",
    "foodSwitzerland[\"originsCat\"] = foodSwitzerland[\"origins\"].str.contains(filter_ch,regex=True).map(place,na_action='ignore')\n",
    "foodSwitzerland[\"manuCat\"] = foodSwitzerland[\"manufacturing_places\"].str.contains(filter_ch,regex=True).map(place,na_action='ignore')\n",
    "foodSwitzerland[\"labCat\"] = foodSwitzerland[\"labels_tags\"].str.contains(filter_local,regex=True).map(refLabel,na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the subdivision in the two periods, taking care of our assumption of 20%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodSwitzerlandBef = foodSwitzerland[foodSwitzerland['created_datetime']<\"2017-03-01 00:00:00\"]\n",
    "foodSwitzerlandAft = foodSwitzerland[foodSwitzerland['created_datetime']>=\"2017-03-01 00:00:00\"]\n",
    "\n",
    "befInAft = foodSwitzerlandAft.sample(n=int(rateOldInNew*len(foodSwitzerlandAft)), replace=False)\n",
    "foodSwitzerlandBef = pd.concat([foodSwitzerlandBef,befInAft],axis=0)\n",
    "\n",
    "for i in range (0,len(befInAft)):\n",
    "    foodSwitzerlandAft = foodSwitzerlandAft[foodSwitzerlandAft['code']!=befInAft['code'].iloc[i]]\n",
    "print(\"Number of Old products: \", np.shape(foodSwitzerlandBef))\n",
    "print(\"Number of New products: \", np.shape(foodSwitzerlandAft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Study of the evolution in time of each one of the interest features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 With respect to: Origin of the primary resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, bootstrapping for include confidence intervals to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before\n",
    "propSB_100ite = np.zeros (100)\n",
    "propOCB_100ite = np.zeros (100)\n",
    "#after\n",
    "propSA_100ite = np.zeros (100)\n",
    "propOCA_100ite = np.zeros (100)\n",
    "\n",
    "for iteration in range(0,100):\n",
    "    #before\n",
    "    temp_bef = foodSwitzerlandBef[\"originsCat\"].sample(n=len(foodSwitzerlandBef), replace=True)\n",
    "    propSB_100ite[iteration] = (sum(temp_bef==\"Switzerland\")/len(foodSwitzerlandBef))\n",
    "    propOCB_100ite[iteration] = sum(temp_bef==\"Other country\")/len(foodSwitzerlandBef)\n",
    "    #after\n",
    "    temp_aft = foodSwitzerlandAft[\"originsCat\"].sample(n=len(foodSwitzerlandAft), replace=True)\n",
    "    propSA_100ite[iteration] = sum(temp_aft==\"Switzerland\")/len(foodSwitzerlandAft)\n",
    "    propOCA_100ite[iteration] = sum(temp_aft==\"Other country\")/len(foodSwitzerlandAft)\n",
    "    \n",
    "    #Relation of time evolution and difference of products in each categories\n",
    "    difpropB = propSB_100ite[iteration]-propOCB_100ite[iteration]\n",
    "    difpropA = propSB_100ite[iteration]-propOCA_100ite[iteration]\n",
    "\n",
    "#Calculating standard deviation of count of each category\n",
    "SBstd = np.std(propSB_100ite)\n",
    "OCBstd = np.std(propOCB_100ite)\n",
    "#Calculating standard deviation of count of each category\n",
    "SAstd = propSA_100ite.std()\n",
    "OCAstd = propOCA_100ite.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, plotting of behavior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Report information of NAN cases\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "print(\"There was not information for \",len(foodSwitzerlandBef[\"originsCat\"])-sum(foodSwitzerlandBef[\"originsCat\"]==\"Switzerland\")-sum(foodSwitzerlandBef[\"originsCat\"]==\"Other country\"),\" products in the period 1.\")\n",
    "print(\"There was not information for \",len(foodSwitzerlandAft[\"originsCat\"])-sum(foodSwitzerlandAft[\"originsCat\"]==\"Switzerland\")-sum(foodSwitzerlandAft[\"originsCat\"]==\"Other country\"),\" products in the period 2.\")\n",
    "\n",
    "#Plot origin of primary resources by periods\n",
    "plt.subplot(1,2,1)\n",
    "(foodSwitzerlandBef[\"originsCat\"].value_counts()/len(foodSwitzerlandBef[\"originsCat\"])).plot(kind='bar', yerr = [SBstd,OCBstd],title='Period 1')\n",
    "plt.subplot(1,2,2)\n",
    "(foodSwitzerlandAft[\"originsCat\"].value_counts()/len(foodSwitzerlandAft[\"originsCat\"])).plot(kind='bar', yerr = [SAstd,OCAstd],title='Period 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of old products have as origin of primary resources Switzerland. However, in new products, the origin of primary resources is for Switzerland and Other countries statistically the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 With respect to: Manufacture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, bootstrapping for include confidence intervals to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before\n",
    "propSB_100ite = np.zeros (100)\n",
    "propOCB_100ite = np.zeros (100)\n",
    "\n",
    "#after\n",
    "propSA_100ite = np.zeros (100)\n",
    "propOCA_100ite = np.zeros (100)\n",
    "\n",
    "for iteration in range(0,100):\n",
    "    #before\n",
    "    temp_bef = foodSwitzerlandBef[\"manuCat\"].sample(n=len(foodSwitzerlandBef), replace=True)\n",
    "    propSB_100ite[iteration] = sum(temp_bef==\"Switzerland\")/len(foodSwitzerlandBef)\n",
    "    propOCB_100ite[iteration] = sum(temp_bef==\"Other country\")/len(foodSwitzerlandBef)\n",
    "    #after\n",
    "    temp_aft = foodSwitzerlandAft[\"manuCat\"].sample(n=len(foodSwitzerlandAft), replace=True)\n",
    "    propSA_100ite[iteration] = sum(temp_aft==\"Switzerland\")/len(foodSwitzerlandAft)\n",
    "    propOCA_100ite[iteration] = sum(temp_aft==\"Other country\")/len(foodSwitzerlandAft)\n",
    "    \n",
    "\n",
    "#Calculating standard deviation of count of each category\n",
    "SBstd = propSB_100ite.std()\n",
    "OCBstd = propOCB_100ite.std()\n",
    "#Calculating standard deviation of count of each category\n",
    "SAstd = propSA_100ite.std()\n",
    "OCAstd = propOCA_100ite.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Report information of NAN cases\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "print(\"There was not information for \",len(foodSwitzerlandBef[\"manuCat\"])-sum(foodSwitzerlandBef[\"manuCat\"]==\"Switzerland\")-sum(foodSwitzerlandBef[\"manuCat\"]==\"Other country\"),\" products in the period 1.\")\n",
    "print(\"There was not information for \",len(foodSwitzerlandAft[\"manuCat\"])-sum(foodSwitzerlandAft[\"manuCat\"]==\"Switzerland\")-sum(foodSwitzerlandAft[\"manuCat\"]==\"Other country\"),\" products in the period 2.\")\n",
    "\n",
    "#Plot origin of primary resources by periods\n",
    "plt.subplot(1,2,1)\n",
    "(foodSwitzerlandBef[\"manuCat\"].value_counts()/len(foodSwitzerlandBef[\"manuCat\"])).plot(kind='bar', yerr = [SBstd,OCBstd],title='Period 1')\n",
    "plt.subplot(1,2,2)\n",
    "(foodSwitzerlandAft[\"manuCat\"].value_counts()/len(foodSwitzerlandBef[\"manuCat\"])).plot(kind='bar', yerr = [SAstd,OCAstd],title='Period 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of old products were manufactured in Switzerland. However, in new products, the manufacture is for Switzerland and Other countries statistically the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 With respect to: Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before\n",
    "propSB_100ite = np.zeros (100)\n",
    "propOCB_100ite = np.zeros (100)\n",
    "#after\n",
    "propSA_100ite = np.zeros (100)\n",
    "propOCA_100ite = np.zeros (100)\n",
    "\n",
    "for iteration in range(0,100):\n",
    "    #before\n",
    "    temp_bef = foodSwitzerlandBef[\"labCat\"].sample(n=len(foodSwitzerlandBef), replace=True)\n",
    "    propSB_100ite[iteration] = sum(temp_bef==\"Related with Switzerland\")/len(foodSwitzerlandBef)\n",
    "    propOCB_100ite[iteration] = sum(temp_bef==\"Other Label\")/len(foodSwitzerlandBef)\n",
    "    #after\n",
    "    temp_aft = foodSwitzerlandAft[\"labCat\"].sample(n=len(foodSwitzerlandAft), replace=True)\n",
    "    propSA_100ite[iteration] = sum(temp_aft==\"Related with Switzerland\")/len(foodSwitzerlandAft)\n",
    "    propOCA_100ite[iteration] = sum(temp_aft==\"Other Label\")/len(foodSwitzerlandAft)\n",
    "    \n",
    "    #Relation of time evolution and difference of products in each categories\n",
    "    difpropB = propSB_100ite[iteration]-propOCB_100ite[iteration]\n",
    "    difpropA = propSB_100ite[iteration]-propOCA_100ite[iteration]\n",
    "\n",
    "#Calculating standard deviation of count of each category\n",
    "SBstd = propSB_100ite.std()\n",
    "OCBstd = propOCB_100ite.std()\n",
    "#Calculating standard deviation of count of each category\n",
    "SAstd = propSA_100ite.std()\n",
    "OCAstd = propOCA_100ite.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Report information of NAN cases\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "print(\"There was not information for \",len(foodSwitzerlandBef[\"labCat\"])-sum(foodSwitzerlandBef[\"labCat\"]==\"Switzerland\")-sum(foodSwitzerlandBef[\"labCat\"]==\"Other country\"),\" products in the period 1.\")\n",
    "print(\"There was not information for \",len(foodSwitzerlandAft[\"labCat\"])-sum(foodSwitzerlandAft[\"labCat\"]==\"Switzerland\")-sum(foodSwitzerlandAft[\"labCat\"]==\"Other country\"),\" products in the period 2.\")\n",
    "\n",
    "#Plot origin of primary resources by periods\n",
    "plt.subplot(1,2,1)\n",
    "(foodSwitzerlandBef[\"labCat\"].value_counts()/len(foodSwitzerlandBef[\"labCat\"])).plot(kind='bar', yerr = [SBstd,OCBstd],title='Period 1')\n",
    "plt.subplot(1,2,2)\n",
    "(foodSwitzerlandAft[\"labCat\"].value_counts()/len(foodSwitzerlandBef[\"labCat\"])).plot(kind='bar', yerr = [SAstd,OCAstd],title='Period 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the two periods studied, other labels are more frequent than the related with Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving data cleaning for countries \n",
    "\n",
    "Although we cleaned the data of name of countries but about 200 are still remained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend research questions to Europe\n",
    "\n",
    "After talking with TA, we decided to extend our research questions to Europe in order to have more data. The similar approach will be taken for answering our main questions about Europe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and complement our results\n",
    "\n",
    "We would like to complement our results using following databases:\n",
    "- Additional datasets “Evolution de la consommation de denrées alimentaires en Suisse” (https://opendata.swiss/fr/dataset/entwicklung-des-nahrungsmittelverbrauches-in-der-schweiz-je-kopf-und-jahr1) and “Dépenses fédérales pour l’agriculture et l’alimentation” (https://opendata.swiss/fr/dataset/bundesausgaben-fur-die-landwirtschaft-und-die-ernahrung1) from https://opendata.swiss/fr/group/agriculture\n",
    "\n",
    "- A last additional dataset for the second question of the project https://www.gate.ezv.admin.ch/swissimpex/public/bereiche/waren/result.xhtml Total of imports of agriculture, forestry and fishing goods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most important characteristic of Swiss-made products\n",
    "\n",
    "After answering our main research questions we would like to find which products are likely to import to Switzerland. To answer this question we would like to train a classifier in order to see which features are the most important features to decide if a product is Swiss made or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve our assumption about date of entering products to the Swiss market\n",
    "\n",
    "Study of the evolution in time of the interest features combined\n",
    "- The k-modes and other machine learning algorithms are expected to be done for the milestone 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
