{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are we consuming more local?\n",
    "\n",
    "## Research questions\n",
    "\n",
    "1. Where are the products we consume in our everyday life coming from?\n",
    "\n",
    "    - Which countries produce the primary resources (ground ingredients) consumed in Switzerland?\n",
    "    - Which countries manufacture most of the products consumed in Switzerland?\n",
    "\n",
    "\n",
    "2. Is there a trend over time to consume more local products?\n",
    "\n",
    "    - Are new products mostly using primary resources from Switzerland? Or from other countries inside Europe?\n",
    "    - Are new products mostly manufactured in Switzerland? Or from other countries inside Europe?\n",
    "    - Is there a trend over time to local products to promote their origin?\n",
    "\n",
    "## Datasets\n",
    "\n",
    "Open Food Facts (https://world.openfoodfacts.org/data)\n",
    "\n",
    "Additional datasets “Evolution de la consommation de denrées alimentaires en Suisse” (https://opendata.swiss/fr/dataset/entwicklung-des-nahrungsmittelverbrauches-in-der-schweiz-je-kopf-und-jahr1) and “Dépenses fédérales pour l’agriculture et l’alimentation” (https://opendata.swiss/fr/dataset/bundesausgaben-fur-die-landwirtschaft-und-die-ernahrung1) from https://opendata.swiss/fr/group/agriculture\n",
    "\n",
    "A last additional dataset for the second question of the project\n",
    "https://www.gate.ezv.admin.ch/swissimpex/public/bereiche/waren/result.xhtml\n",
    "Total of imports of agriculture, forestry and fishing goods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import min\n",
    "from pyspark.sql.functions import to_date, last_day,date_add\n",
    "from datetime import timedelta\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "openfood_file = \"/en.openfoodfacts.org.products.csv\"\n",
    "PARQUET_PATH = 'output/data.parquet'\n",
    "temp_file = 'output/temp.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main = spark.read.csv(DATA_FOLDER+ openfood_file, header=True, mode=\"DROPMALFORMED\", sep = '\\t')\n",
    "\n",
    "dataset_main.createOrReplaceTempView(\"data_main\")\n",
    "\n",
    "# Filter required columns\n",
    "p_id_col = \" code, product_name, \"\n",
    "general_cols = \" brands, brands_tags, categories, categories_tags, origins, origins_tags, manufacturing_places, manufacturing_places_tags,labels,labels_tags,emb_codes,emb_codes_tags,first_packaging_code_geo,cities,cities_tags,purchase_places,stores,countries,countries_tags \"\n",
    "geo_cols = \" origins, manufacturing_places, countries \"\n",
    "geo_tags_cols = \" origins_tags, manufacturing_places_tags, countries_tags \"\n",
    "\n",
    "off_df = spark.sql(\"SELECT\" + p_id_col + geo_tags_cols + \" FROM data_main\")\n",
    "off_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_df.createOrReplaceTempView(\"off_df\")\n",
    "\n",
    "sql_filter = \"SELECT * FROM off_df WHERE countries_tags is not NULL AND manufacturing_places_tags is not NULL AND origins_tags is not NULL\"\n",
    "off_p_df = spark.sql(sql_filter)\n",
    "\n",
    "# off_p_all_size = off_p_df.count()\n",
    "# off_p_cols_size = len(off_p_df.columns)\n",
    "# print(\"Full GEO information data Size:\\n\" + str(off_p_cols_size) + \"(columns) * \" + str(off_p_all_size) + \"(rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode countries\n",
    "off_p_df = off_p_df.withColumn('origins_tags', F.explode_outer(F.split('origins_tags', ',')))\\\n",
    ".withColumn('manufacturing_places_tags', F.explode_outer(F.split('manufacturing_places_tags', ',')))\\\n",
    ".withColumn('countries_tags', F.explode_outer(F.split('countries_tags', ',')))\n",
    "\n",
    "# Remove \"en:\" occurances before name of each country in coutries_tags\n",
    "off_p_df = off_p_df.withColumn('countries_tags', F.regexp_replace('countries_tags', \"en:\", \"\"))\n",
    "# Remove - in name of countries\n",
    "off_p_df = off_p_df.withColumn('countries_tags', F.regexp_replace('countries_tags', \"-\", \" \"))\n",
    "off_p_df = off_p_df.withColumn('manufacturing_places_tags', F.regexp_replace('manufacturing_places_tags', \"-\", \" \"))\n",
    "off_p_df = off_p_df.withColumn('origins_tags', F.regexp_replace('origins_tags', \"-\", \" \"))\n",
    "\n",
    "# Remove numbers from name of countries\n",
    "off_p_df = off_p_df.withColumn('countries_tags', F.regexp_replace('countries_tags', \"\\d+\", \"\"))\n",
    "off_p_df = off_p_df.withColumn('manufacturing_places_tags', F.regexp_replace('countries_tags', \"\\d+\", \"\"))\n",
    "off_p_df = off_p_df.withColumn('origins_tags', F.regexp_replace('origins_tags', \"\\d+\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_p_df = off_p_df.withColumn(\"countries\", off_p_df[\"countries_tags\"])\n",
    "off_p_df = off_p_df.withColumn(\"manufacturing_places\", off_p_df[\"manufacturing_places_tags\"])\n",
    "off_p_df = off_p_df.withColumn(\"origins\", off_p_df[\"origins_tags\"])\n",
    "off_p_df = off_p_df.withColumn(\"is_eu\", lit(0))\n",
    "off_p_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_p_all_size = off_p_df.count()\n",
    "off_p_cols_size = len(off_p_df.columns)\n",
    "print(\"Full GEO information data Size:\\n\" + str(off_p_cols_size) + \"(columns) * \" + str(off_p_all_size) + \"(rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['c_countries'] = \"\"\n",
    "# df['c_manufacturing_places'] = \"\"\n",
    "# df['c_origins'] = \"\"\n",
    "# df['sold_in_EU'] = 0\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     output = cleaned_countries[cleaned_countries.input.str.contains(row.origins_tags, case=False, na=False)]\n",
    "#     if len(output):\n",
    "#         row.c_origins = output.iloc[0].country_code\n",
    "        \n",
    "#     output = cleaned_countries[cleaned_countries.input.str.contains(row.manufacturing_places_tags, case=False, na=False)]\n",
    "#     if len(output):\n",
    "#         row.c_manufacturing_places = output.iloc[0].country_code\n",
    "        \n",
    "#     output = cleaned_countries[cleaned_countries.input.str.contains(row.countries_tags, case=False, na=False)]\n",
    "#     if len(output):\n",
    "#         row.c_countries = output.iloc[0].country_code\n",
    "        \n",
    "#     output = eu_countries[eu_countries.str.contains(row.c_countries, case=False, na=False)]\n",
    "#     if len(output):\n",
    "#         row.sold_in_EU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>input</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>france</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>canada</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>germany</td>\n",
       "      <td>gm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>vietnam</td>\n",
       "      <td>vm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           input country_code\n",
       "0           0          france           fr\n",
       "1           1  united kingdom           uk\n",
       "2           2          canada           ca\n",
       "3           3         germany           gm\n",
       "4           4         vietnam           vm"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean countries\n",
    "cleaned_countries= pd.read_csv(DATA_FOLDER+ \"/mapping_countries.csv\",sep=',', error_bad_lines=False, encoding = \"utf-8\")\n",
    "cleaned_countries['country_code'] = cleaned_countries['country_code'].str.lower()\n",
    "cleaned_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = 4500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "7100\n",
      "Seen: 7150\n"
     ]
    }
   ],
   "source": [
    "interval = 501\n",
    "if seen:\n",
    "#     off_p_df = spark.read.parquet(PARQUET_PATH)\n",
    "    off_p_df = spark.read.csv(temp_file, header=True)\n",
    "\n",
    "# Clean origins countries\n",
    "for index, row in cleaned_countries.head(seen + interval).iterrows():\n",
    "        if index < seen:\n",
    "            continue\n",
    "        if index%100 == 0:\n",
    "            print(index)\n",
    "        off_p_df = off_p_df.withColumn('origins', F.regexp_replace('countries', \"^\" + str(row['input']) + \"$\", row['country_code']))\n",
    "        off_p_df = off_p_df.withColumn('manufacturing_places', F.regexp_replace('manufacturing_places', \"^\" + str(row['input']) + \"$\", row['country_code']))\n",
    "        off_p_df = off_p_df.withColumn('countries', F.regexp_replace('countries', \"^\" + str(row['input']) + \"$\", row['country_code']))\n",
    "        seen = index\n",
    "\n",
    "# Save Spark dataframe in the Parquet format\n",
    "# off_p_df.write.mode('overwrite').parquet(PARQUET_PATH)\n",
    "off_p_df.toPandas().to_csv(temp_file, index=False)\n",
    "\n",
    "print(\"Seen: {0}\".format(seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------------+-------------------------+--------------+---------+--------------------+-------+-----+\n",
      "|         code|        product_name|origins_tags|manufacturing_places_tags|countries_tags|countries|manufacturing_places|origins|is_eu|\n",
      "+-------------+--------------------+------------+-------------------------+--------------+---------+--------------------+-------+-----+\n",
      "|0000000274722|Blanquette de Vol...|      france|                   france|        france|       ct|                  ct|     ct|    0|\n",
      "|0000000290616|        Salade Cesar|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000000394710|Danoises à la can...|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000001071894|               Flute|      france|           united kingdom|united kingdom|       up|                  up|     up|    0|\n",
      "|0000001938067|Chaussons tressés...|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000004302544| Pain Burger Artisan|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000004302544| Pain Burger Artisan|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000008237798|     Quiche Lorraine|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000008237798|     Quiche Lorraine|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000008240095|      Pâté au poulet|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000012167005|Brioches roulées ...|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000012167005|Brioches roulées ...|      quebec|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000012167005|Brioches roulées ...|      canada|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000012167005|Brioches roulées ...|      canada|                   canada|        canada|       aq|                  aq|     aq|    0|\n",
      "|0000020004552|Côtes du Rhône Vi...|      france|                   france|        france|       ct|                  ct|     ct|    0|\n",
      "|0000034152010|      Reese's sticks|      france|                   france|        france|       ct|                  ct|     ct|    0|\n",
      "|0000204286484|Mehrkomponeneten ...|     germany|                  germany|       germany|       gm|                  gm|     gm|    0|\n",
      "|0000204286644|Mehrkomponeneten ...|     germany|                  germany|       germany|       gm|                  gm|     gm|    0|\n",
      "|0000250632969|Mehrkomponeneten ...|     germany|                  germany|       germany|       gm|                  gm|     gm|    0|\n",
      "|     00003100|    Chair à saucisse|      france|                   france|        france|       ct|                  ct|     ct|    0|\n",
      "+-------------+--------------------+------------+-------------------------+--------------+---------+--------------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "off_p_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_p_all_size = off_p_df.count()\n",
    "off_p_cols_size = len(off_p_df.columns)\n",
    "print(\"Full GEO information data Size:\\n\" + str(off_p_cols_size) + \"(columns) * \" + str(off_p_all_size) + \"(rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect european countries\n",
    "eu_countries= pd.read_csv(DATA_FOLDER+ \"/EU-countries.csv\",sep=',', error_bad_lines=False, encoding = \"utf-8\")\n",
    "eu_countries= eu_countries.Code\n",
    "eu_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store products that are sold in Switzerland\n",
    "europe_sold_data = df[df[\"sold_in_EU\"] == 1]\n",
    "\n",
    "print(\"swiss_sold data Size:\\n {0}\".format(len(europe_sold_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now we work on products sold in Switzerland. \n",
    "We classify these products under different categories:\n",
    "- products manufactured in Switzerland\n",
    "- products not manufactured Switzerland to find which countries manufacture the most products consumed in Switzerland.\n",
    "- products not originating from Switzerland to find which countries produce the ground ingredients for products sold in Switzerland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store products which ingredients originate from Switzerland\n",
    "swiss_origin_data = off_p_df.filter(off_p_df[\"origins\"].rlike(filter_ch))\n",
    "\n",
    "swiss_origin_size = swiss_origin_data.count()\n",
    "print(\"swiss_origin data Size:\\n\" + str(swiss_origin_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store products that are manufactured in Switzerland\n",
    "swiss_manu_data = off_p_df.filter(off_p_df[\"manufacturing_places\"].rlike(filter_ch))\n",
    "\n",
    "swiss_manu_size = swiss_manu_data.count()\n",
    "print(\"swiss_manufactored data Size:\\n\" + str(swiss_manu_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store products that are both manufactured and originate from Switzerland\n",
    "swiss_origin_manu_data = off_p_df.filter(off_p_df[\"origins\"].rlike(filter_ch) & off_p_df[\"manufacturing_places\"].rlike(filter_ch))\n",
    "\n",
    "swiss_origin_manu_size = swiss_origin_manu_data.count()\n",
    "print(\"swiss_origin_manufactored data Size:\\n\" + str(swiss_origin_manu_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count products whose ingredients from switzerland but which were not manufactured in Switzerland\n",
    "swiss_origin_tot = swiss_origin_data.filter(~ swiss_origin_data[\"manufacturing_places\"].rlike(filter_ch)).count()\n",
    "\n",
    "#Total of products sold in Switzerland\n",
    "swiss_sold_tot = swiss_sold_data.count()\n",
    "\n",
    "#count products that do not have swiss ingredients\n",
    "swiss_manu_tot = swiss_manu_data.filter(~ swiss_manu_data[\"origins\"].rlike(filter_ch)).count()\n",
    "\n",
    "#products that are sold in Switzerland but that were not manufactured in CH and that do not have swiss ingredients\n",
    "non_swiss_sold_tot = swiss_sold_data.filter(~ swiss_sold_data[\"manufacturing_places\"].rlike(filter_ch) & ~swiss_sold_data[\"origins\"].rlike(filter_ch)).count()\n",
    "\n",
    "#total of products that are both manufactured and has ingredients from Switzerland\n",
    "swiss_origin_manu_tot = swiss_origin_manu_data.count()\n",
    "\n",
    "labels = 'Swiss ingredients (but not manufactured in Switzerland)', 'Manufactured in Switzerland (with no swiss ingredients)', 'Completely foreign products', 'Both swiss ingredients and manufactured in Switzerland'\n",
    "sizes = [swiss_origin_tot, swiss_manu_tot, non_swiss_sold_tot, swiss_origin_manu_tot]\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Proportions for a total of ' + str(swiss_sold_tot) + ' products sold in Switzerland')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to above chart, we can see that Switzerland tend to use local ingredients to manufacture products. Since most of products manufactured in Switzerland are produced by mostly Swiss ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store products that are not manufactured in Switzerland\n",
    "non_swiss_sold = swiss_sold_data.filter(~swiss_sold_data[\"manufacturing_places\"].rlike(filter_ch))\n",
    "\n",
    "non_swiss_sold_size = non_swiss_sold.count()\n",
    "print(\"Non swiss/Sold in Switzerland data Size:\\n\" + str(non_swiss_sold_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store products that are manufactured in Switzerland\n",
    "swiss_m_sold = swiss_sold_data.filter(swiss_sold_data[\"manufacturing_places\"].rlike(filter_ch))\n",
    "\n",
    "swiss_m_sold_size = swiss_m_sold.count()\n",
    "print(\"Swiss/Sold in Switzerland data Size:\\n\" + str(swiss_m_sold_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number Swiss vs non-swiss products (Manufacturing)\n",
    "fig, ax = plt.subplots()\n",
    "titles = ['Manufactured in Switzerland', 'Not manufactured in Switzerland']\n",
    "plt.bar(titles, [swiss_m_sold_size, non_swiss_sold_size])\n",
    "plt.ylabel('Number of products sold in Switzerland')   \n",
    "plt.xticks(titles)\n",
    "plt.title('Fig. Manufacturing products in Switzerland')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of __762__ products sold in Switzerland, Just about __51%__ of them was manufactured in Switzerland."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is not concistent with the country or places name, therefore, we have to clean the data by trying to unify a maximum the places names. First the database http://download.geonames.org/export/dump/ was used in order to match all the different ways of naming a country to a single convention but since there are some rows which need human intelligence to process(for example some fields contain name of ingredient or details) in the end we prefered to clean data manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_countries = pd.read_csv(\"cleaning_data/origins_cleaning.csv\")\n",
    "\n",
    "# Flatten origins column\n",
    "origins_p = non_swiss_sold.withColumn('origins', F.explode_outer(F.split('origins', ',')))\n",
    "\n",
    "# Clean origins countries\n",
    "for index, row in cleaned_countries.iterrows():\n",
    "    if(str(row['replace_with']) != \"nan\"):\n",
    "        origins_p = origins_p.withColumn('origins', F.regexp_replace('origins', \"^\" + row['origins'] + \"$\", row['replace_with']))\n",
    "    else:\n",
    "        origins_p = origins_p.withColumn('origins', F.regexp_replace('origins', row['origins'], \"Not Specified\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dominant importers of ingredients\n",
    "\n",
    "origins_p.createOrReplaceTempView(\"origins_p\")\n",
    "target_origins = spark.sql(\"SELECT origins, COUNT(origins) FROM origins_p GROUP BY origins ORDER BY COUNT(origins) DESC\")\n",
    "target_origins = target_origins.withColumnRenamed('count(origins)' , 'Count')\n",
    "\n",
    "print(\"Number of ingredient importers:\\n\" + str(target_origins.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_origins.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 10 most important countries and number of occurances in ingredients.\n",
    "origin_countries = target_origins.toPandas() \n",
    "origin_countries = origin_countries.head(10)\n",
    "\n",
    "# Plot the number of products imported by 10 most important countries\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(zorder=-1)\n",
    "plt.bar(origin_countries.origins, origin_countries.Count, zorder=3, color='skyblue')\n",
    "plt.ylabel('Number of products')   \n",
    "plt.xticks(origin_countries.origins, rotation='80')\n",
    "plt.title('Fig. The number of products which ingredients are from the 10 most frequent countries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export origins to CSV \n",
    "target_origins.select(\"origins\").toPandas().to_csv('output/origins.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we found the most important countries in case of producing ingredients for products which are imported to Switzerland, We should take the same approach to find the most important manufacturers of this products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten manufacturing_places column\n",
    "manufacturers_p = non_swiss_sold.withColumn('manufacturing_places', F.explode_outer(F.split('manufacturing_places', ',')))\n",
    "\n",
    "# Clean manufacturers countries\n",
    "for index, row in cleaned_countries.iterrows():\n",
    "    if(str(row['replace_with']) != \"nan\"):\n",
    "        manufacturers_p = manufacturers_p.withColumn('manufacturing_places', F.regexp_replace('manufacturing_places', \"^\" + row['origins'] + \"$\", row['replace_with']))\n",
    "    else:\n",
    "        manufacturers_p = manufacturers_p.withColumn('manufacturing_places', F.regexp_replace('manufacturing_places', row['origins'], \"Not Specified\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dominant importers (manufacturers)\n",
    "\n",
    "manufacturers_p.createOrReplaceTempView(\"manufacturers_p\")\n",
    "target_manufacturers = spark.sql(\"SELECT manufacturing_places, COUNT(manufacturing_places) FROM manufacturers_p GROUP BY manufacturing_places ORDER BY COUNT(manufacturing_places) DESC\")\n",
    "target_manufacturers = target_manufacturers.withColumnRenamed('count(manufacturing_places)' , 'Count')\n",
    "# target_manufacturers.show()\n",
    "\n",
    "print(\"Number of Manufacturers:\\n\" + str(target_manufacturers.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 10 most important manufacturers countries and number of occurances.\n",
    "manufacturer_countries = target_manufacturers.toPandas() \n",
    "manufacturer_countries = manufacturer_countries.head(10)\n",
    "\n",
    "# Plot the number of products manufactured by 10 most important countries\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(zorder=-1)\n",
    "plt.bar(manufacturer_countries.manufacturing_places, manufacturer_countries.Count, zorder=3, color='skyblue')\n",
    "plt.ylabel('Number of products')   \n",
    "plt.xticks(manufacturer_countries.manufacturing_places, rotation='80')\n",
    "plt.title('Fig. The number of products manufactured by 10 most important countries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export manufacturing_places to CSV \n",
    "target_manufacturers.select(\"manufacturing_places\").toPandas().to_csv('output/manufacturing_places.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with products' categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to find which countries import what products?\n",
    "In order to answer to this question, first we extract categories corresponding to the products sold in Switzerland but not manufactured in this country. Then we will combine the information provided for manufacturing places of these products with corresponding category. \n",
    "\n",
    "In the end we will extract the 5 most important importers of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_info_df = ' categories '\n",
    "categories_df = spark.sql(\"SELECT\" + p_id_col + extra_info_df + \" FROM data_main\")\n",
    "categories_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in traces_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join table of categories with table of target products (Sold in Switzerland but not manufactured in it)\n",
    "non_swiss_sold.createOrReplaceTempView(\"target_products_df\")\n",
    "categories_df.createOrReplaceTempView(\"categories_df\")\n",
    "joined_df = spark.sql(\"SELECT p.code, c.categories, p.origins, p.manufacturing_places, p.countries  FROM target_products_df p INNER JOIN categories_df c ON p.code = c.code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in joined_df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to above table, just 15 products do not have category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.createOrReplaceTempView(\"target_products_cats\")\n",
    "sql_filter = \"SELECT * FROM target_products_cats WHERE categories is not NULL\"\n",
    "target_products_categories_p = spark.sql(sql_filter)\n",
    "\n",
    "print(\"Number of Products sold in Switzerland with categories:\\n\" + str(target_products_categories_p.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_products_categories_p.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten categories column\n",
    "target_products_categories_p = target_products_categories_p.withColumn('categories', F.explode_outer(F.split('categories', ',')))\n",
    "\n",
    "# Remove occurances of en: in name of categories\n",
    "target_products_categories_p = target_products_categories_p.withColumn('categories', F.regexp_replace('categories', 'en:', ''))\n",
    "\n",
    "target_products_categories_p.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dominant categories\n",
    "target_products_categories_p.createOrReplaceTempView(\"target_products_categories_p\")\n",
    "target_categories = spark.sql(\"SELECT categories, COUNT(categories) FROM target_products_categories_p GROUP BY categories ORDER BY COUNT(categories) DESC\")\n",
    "target_categories = target_categories.withColumnRenamed('count(categories)' , 'Count')\n",
    "target_categories.show()\n",
    "\n",
    "print(\"Number of Categories:\\n\" + str(target_categories.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to above table not all categories are independant and they may contain similar products. We did not change categories for this milestone but we would like to merge some categories in future to have better distinction between countries which import these products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Categories to CSV \n",
    "target_categories.toPandas().to_csv('output/categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 15 most frequent categories and number of occurances.\n",
    "categories = target_categories.toPandas() \n",
    "categories = categories.head(15)\n",
    "\n",
    "# Plot the most frequent categories\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(zorder=-1)\n",
    "plt.barh(categories.categories, categories.Count, zorder=3, color='skyblue')\n",
    "plt.xlabel('Number of products')   \n",
    "plt.title('Fig. The number of products sold in Switzerland')\n",
    "ax.invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_countries = pd.read_csv(\"cleaning_data/origins_cleaning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the most important manufacturer countries for 15 most frequent categories\n",
    "\n",
    "categories_countires_p = target_products_categories_p.withColumn('manufacturing_places', F.explode_outer(F.split('manufacturing_places', ',')))\n",
    "\n",
    "# Clean manufacturers countries\n",
    "for index, row in cleaned_countries.iterrows():\n",
    "    if(str(row['replace_with']) != \"nan\"):\n",
    "        categories_countires_p = categories_countires_p.withColumn('manufacturing_places', F.regexp_replace('manufacturing_places', \"^\" + row['origins'] + \"$\", row['replace_with']))\n",
    "    else:\n",
    "        categories_countires_p = categories_countires_p.withColumn('manufacturing_places', F.regexp_replace('manufacturing_places', row['origins'], \"Not Specified\"))\n",
    "\n",
    "categories_countires_p = categories_countires_p.withColumn('categories', F.explode_outer(F.split('categories', ',')))\n",
    "products_cats_df = categories_countires_p.toPandas()\n",
    "\n",
    "countries_cats = []\n",
    "cat = \"Snacks sucrés\"\n",
    "for index, row in categories.iterrows():\n",
    "    temp_df = products_cats_df[(products_cats_df.categories == row.categories)].groupby('manufacturing_places').count().sort_values(by=['code'], ascending=False).head(5)\n",
    "    countries_cats.append(temp_df)\n",
    "\n",
    "# Each element of countries_cats is a dataframe containing the most important manufacturers\n",
    "# of the corresponding category\n",
    "\n",
    "i = 0\n",
    "print(\"category: \" + str(categories.iloc[i].categories))\n",
    "print(\"The most important manufacturers:\")\n",
    "print(countries_cats[0].head(3).index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use extracted information about the most important manufacturer countries for 15 most frequent categories for our visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openfood = pd.read_csv(DATA_FOLDER + openfood_file, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodSwitzerland = openfood[openfood['countries_tags']==\"en:switzerland\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbProdSwit = len(foodSwitzerland)\n",
    "print(\"Number of products: \", nbProdSwit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first perspective: Compare old vs new products inside the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A product in the dataset is considered \"old\" if its description was uploaded to the dataset before February 2017. By the contrary, it is considered as \"new\" if its description was uploaded after that date.\n",
    "\n",
    "_As that definition is a little rigid, in order to get closer to the real situation, the following assumption is made: From the total products uploaded to the dataset after February 2017, 20% are old products._  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first perspective to tackle the research question, is to compare how in this more than 6 years of existance of the dataset, the characteristics of the products have changed. Specifically, we would like to know if there have been some changes in the origin of the primary resources, or in the origin of the manufacture or in the labels of the products.\n",
    "\n",
    "The study of the evolution in time of each one of those features, will include an __exploratory data analysis__.\n",
    "Finally, a study including the three features will be done, aiming to find an aggregated differentiated behavior in time, reflected in different clusters of periods of time. For that the __K-modes algorithm__ will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Date of first upload: \", min(foodSwitzerland['created_datetime']))\n",
    "print(\"Date of last upload retrieved: \", max(foodSwitzerland['created_datetime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodSwitzerland['created_datetime'] = pd.to_datetime(foodSwitzerland['created_datetime'])\n",
    "foodSwitzerland = foodSwitzerland.sort_values(by='created_datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uploads of products sold in Switzerland, behaves differently in time. Taking into account the histogram presented below, two periods of time are defined:\n",
    "- Period 1: Created for studying the behaviour from \"old\" products. Products uploaded before Feb 2017.\n",
    "- Period 2: Created for studying the behaviour from \"new\" products. Products uploaded after Feb 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateOldInNew = 0.2\n",
    "old_products = len(foodSwitzerland[foodSwitzerland['created_datetime']<\"2017-03-01 00:00:00\"])\n",
    "print(\"Old products: \", old_products + (len(foodSwitzerland)-old_products)*(rateOldInNew))\n",
    "print(\"New products: \", (len(foodSwitzerland)-old_products)*(1-rateOldInNew))\n",
    "foodSwitzerland['created_datetime'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making subdivision of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ch = '[Ss]witzerland|[Ss]uisse|[Ss]chweiz|[Ss]vizerra'\n",
    "filter_local = '[Ss]witzerland|[Ss]uisse|[Ss]chweiz|[Ss]vizerra|[Ll]ocal'\n",
    "\n",
    "place = pd.Series(['Other country','Switzerland', 'No information'], index=[0,1,2])\n",
    "refLabel = pd.Series(['Other Label','Related with Switzerland', 'No information'], index=[0,1,2]) \n",
    "\n",
    "foodSwitzerland[\"originsCat\"] = foodSwitzerland[\"origins\"].str.contains(filter_ch,regex=True).map(place,na_action='ignore')\n",
    "foodSwitzerland[\"manuCat\"] = foodSwitzerland[\"manufacturing_places\"].str.contains(filter_ch,regex=True).map(place,na_action='ignore')\n",
    "foodSwitzerland[\"labCat\"] = foodSwitzerland[\"labels_tags\"].str.contains(filter_local,regex=True).map(refLabel,na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the subdivision in the two periods, taking care of our assumption of 20%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodSwitzerlandBef = foodSwitzerland[foodSwitzerland['created_datetime']<\"2017-03-01 00:00:00\"]\n",
    "foodSwitzerlandAft = foodSwitzerland[foodSwitzerland['created_datetime']>=\"2017-03-01 00:00:00\"]\n",
    "\n",
    "befInAft = foodSwitzerlandAft.sample(n=int(rateOldInNew*len(foodSwitzerlandAft)), replace=False)\n",
    "foodSwitzerlandBef = pd.concat([foodSwitzerlandBef,befInAft],axis=0)\n",
    "\n",
    "for i in range (0,len(befInAft)):\n",
    "    foodSwitzerlandAft = foodSwitzerlandAft[foodSwitzerlandAft['code']!=befInAft['code'].iloc[i]]\n",
    "print(\"Number of Old products: \", np.shape(foodSwitzerlandBef))\n",
    "print(\"Number of New products: \", np.shape(foodSwitzerlandAft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Study of the evolution in time of each one of the interest features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 With respect to: Origin of the primary resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, bootstrapping for include confidence intervals to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before\n",
    "propSB_100ite = np.zeros (100)\n",
    "propOCB_100ite = np.zeros (100)\n",
    "#after\n",
    "propSA_100ite = np.zeros (100)\n",
    "propOCA_100ite = np.zeros (100)\n",
    "\n",
    "for iteration in range(0,100):\n",
    "    #before\n",
    "    temp_bef = foodSwitzerlandBef[\"originsCat\"].sample(n=len(foodSwitzerlandBef), replace=True)\n",
    "    propSB_100ite[iteration] = (sum(temp_bef==\"Switzerland\")/len(foodSwitzerlandBef))\n",
    "    propOCB_100ite[iteration] = sum(temp_bef==\"Other country\")/len(foodSwitzerlandBef)\n",
    "    #after\n",
    "    temp_aft = foodSwitzerlandAft[\"originsCat\"].sample(n=len(foodSwitzerlandAft), replace=True)\n",
    "    propSA_100ite[iteration] = sum(temp_aft==\"Switzerland\")/len(foodSwitzerlandAft)\n",
    "    propOCA_100ite[iteration] = sum(temp_aft==\"Other country\")/len(foodSwitzerlandAft)\n",
    "    \n",
    "    #Relation of time evolution and difference of products in each categories\n",
    "    difpropB = propSB_100ite[iteration]-propOCB_100ite[iteration]\n",
    "    difpropA = propSB_100ite[iteration]-propOCA_100ite[iteration]\n",
    "\n",
    "#Calculating standard deviation of count of each category\n",
    "SBstd = np.std(propSB_100ite)\n",
    "OCBstd = np.std(propOCB_100ite)\n",
    "#Calculating standard deviation of count of each category\n",
    "SAstd = propSA_100ite.std()\n",
    "OCAstd = propOCA_100ite.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, plotting of behavior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Report information of NAN cases\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "print(\"There was not information for \",len(foodSwitzerlandBef[\"originsCat\"])-sum(foodSwitzerlandBef[\"originsCat\"]==\"Switzerland\")-sum(foodSwitzerlandBef[\"originsCat\"]==\"Other country\"),\" products in the period 1.\")\n",
    "print(\"There was not information for \",len(foodSwitzerlandAft[\"originsCat\"])-sum(foodSwitzerlandAft[\"originsCat\"]==\"Switzerland\")-sum(foodSwitzerlandAft[\"originsCat\"]==\"Other country\"),\" products in the period 2.\")\n",
    "\n",
    "#Plot origin of primary resources by periods\n",
    "plt.subplot(1,2,1)\n",
    "(foodSwitzerlandBef[\"originsCat\"].value_counts()/len(foodSwitzerlandBef[\"originsCat\"])).plot(kind='bar', yerr = [SBstd,OCBstd],title='Period 1')\n",
    "plt.subplot(1,2,2)\n",
    "(foodSwitzerlandAft[\"originsCat\"].value_counts()/len(foodSwitzerlandAft[\"originsCat\"])).plot(kind='bar', yerr = [SAstd,OCAstd],title='Period 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of old products have as origin of primary resources Switzerland. However, in new products, the origin of primary resources is for Switzerland and Other countries statistically the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 With respect to: Manufacture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, bootstrapping for include confidence intervals to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before\n",
    "propSB_100ite = np.zeros (100)\n",
    "propOCB_100ite = np.zeros (100)\n",
    "\n",
    "#after\n",
    "propSA_100ite = np.zeros (100)\n",
    "propOCA_100ite = np.zeros (100)\n",
    "\n",
    "for iteration in range(0,100):\n",
    "    #before\n",
    "    temp_bef = foodSwitzerlandBef[\"manuCat\"].sample(n=len(foodSwitzerlandBef), replace=True)\n",
    "    propSB_100ite[iteration] = sum(temp_bef==\"Switzerland\")/len(foodSwitzerlandBef)\n",
    "    propOCB_100ite[iteration] = sum(temp_bef==\"Other country\")/len(foodSwitzerlandBef)\n",
    "    #after\n",
    "    temp_aft = foodSwitzerlandAft[\"manuCat\"].sample(n=len(foodSwitzerlandAft), replace=True)\n",
    "    propSA_100ite[iteration] = sum(temp_aft==\"Switzerland\")/len(foodSwitzerlandAft)\n",
    "    propOCA_100ite[iteration] = sum(temp_aft==\"Other country\")/len(foodSwitzerlandAft)\n",
    "    \n",
    "\n",
    "#Calculating standard deviation of count of each category\n",
    "SBstd = propSB_100ite.std()\n",
    "OCBstd = propOCB_100ite.std()\n",
    "#Calculating standard deviation of count of each category\n",
    "SAstd = propSA_100ite.std()\n",
    "OCAstd = propOCA_100ite.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Report information of NAN cases\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "print(\"There was not information for \",len(foodSwitzerlandBef[\"manuCat\"])-sum(foodSwitzerlandBef[\"manuCat\"]==\"Switzerland\")-sum(foodSwitzerlandBef[\"manuCat\"]==\"Other country\"),\" products in the period 1.\")\n",
    "print(\"There was not information for \",len(foodSwitzerlandAft[\"manuCat\"])-sum(foodSwitzerlandAft[\"manuCat\"]==\"Switzerland\")-sum(foodSwitzerlandAft[\"manuCat\"]==\"Other country\"),\" products in the period 2.\")\n",
    "\n",
    "#Plot origin of primary resources by periods\n",
    "plt.subplot(1,2,1)\n",
    "(foodSwitzerlandBef[\"manuCat\"].value_counts()/len(foodSwitzerlandBef[\"manuCat\"])).plot(kind='bar', yerr = [SBstd,OCBstd],title='Period 1')\n",
    "plt.subplot(1,2,2)\n",
    "(foodSwitzerlandAft[\"manuCat\"].value_counts()/len(foodSwitzerlandBef[\"manuCat\"])).plot(kind='bar', yerr = [SAstd,OCAstd],title='Period 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of old products were manufactured in Switzerland. However, in new products, the manufacture is for Switzerland and Other countries statistically the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 With respect to: Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before\n",
    "propSB_100ite = np.zeros (100)\n",
    "propOCB_100ite = np.zeros (100)\n",
    "#after\n",
    "propSA_100ite = np.zeros (100)\n",
    "propOCA_100ite = np.zeros (100)\n",
    "\n",
    "for iteration in range(0,100):\n",
    "    #before\n",
    "    temp_bef = foodSwitzerlandBef[\"labCat\"].sample(n=len(foodSwitzerlandBef), replace=True)\n",
    "    propSB_100ite[iteration] = sum(temp_bef==\"Related with Switzerland\")/len(foodSwitzerlandBef)\n",
    "    propOCB_100ite[iteration] = sum(temp_bef==\"Other Label\")/len(foodSwitzerlandBef)\n",
    "    #after\n",
    "    temp_aft = foodSwitzerlandAft[\"labCat\"].sample(n=len(foodSwitzerlandAft), replace=True)\n",
    "    propSA_100ite[iteration] = sum(temp_aft==\"Related with Switzerland\")/len(foodSwitzerlandAft)\n",
    "    propOCA_100ite[iteration] = sum(temp_aft==\"Other Label\")/len(foodSwitzerlandAft)\n",
    "    \n",
    "    #Relation of time evolution and difference of products in each categories\n",
    "    difpropB = propSB_100ite[iteration]-propOCB_100ite[iteration]\n",
    "    difpropA = propSB_100ite[iteration]-propOCA_100ite[iteration]\n",
    "\n",
    "#Calculating standard deviation of count of each category\n",
    "SBstd = propSB_100ite.std()\n",
    "OCBstd = propOCB_100ite.std()\n",
    "#Calculating standard deviation of count of each category\n",
    "SAstd = propSA_100ite.std()\n",
    "OCAstd = propOCA_100ite.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Report information of NAN cases\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "print(\"There was not information for \",len(foodSwitzerlandBef[\"labCat\"])-sum(foodSwitzerlandBef[\"labCat\"]==\"Switzerland\")-sum(foodSwitzerlandBef[\"labCat\"]==\"Other country\"),\" products in the period 1.\")\n",
    "print(\"There was not information for \",len(foodSwitzerlandAft[\"labCat\"])-sum(foodSwitzerlandAft[\"labCat\"]==\"Switzerland\")-sum(foodSwitzerlandAft[\"labCat\"]==\"Other country\"),\" products in the period 2.\")\n",
    "\n",
    "#Plot origin of primary resources by periods\n",
    "plt.subplot(1,2,1)\n",
    "(foodSwitzerlandBef[\"labCat\"].value_counts()/len(foodSwitzerlandBef[\"labCat\"])).plot(kind='bar', yerr = [SBstd,OCBstd],title='Period 1')\n",
    "plt.subplot(1,2,2)\n",
    "(foodSwitzerlandAft[\"labCat\"].value_counts()/len(foodSwitzerlandBef[\"labCat\"])).plot(kind='bar', yerr = [SAstd,OCAstd],title='Period 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the two periods studied, other labels are more frequent than the related with Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving data cleaning for countries \n",
    "\n",
    "Although we cleaned the data of name of countries but about 200 are still remained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend research questions to Europe\n",
    "\n",
    "After talking with TA, we decided to extend our research questions to Europe in order to have more data. The similar approach will be taken for answering our main questions about Europe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and complement our results\n",
    "\n",
    "We would like to complement our results using following databases:\n",
    "- Additional datasets “Evolution de la consommation de denrées alimentaires en Suisse” (https://opendata.swiss/fr/dataset/entwicklung-des-nahrungsmittelverbrauches-in-der-schweiz-je-kopf-und-jahr1) and “Dépenses fédérales pour l’agriculture et l’alimentation” (https://opendata.swiss/fr/dataset/bundesausgaben-fur-die-landwirtschaft-und-die-ernahrung1) from https://opendata.swiss/fr/group/agriculture\n",
    "\n",
    "- A last additional dataset for the second question of the project https://www.gate.ezv.admin.ch/swissimpex/public/bereiche/waren/result.xhtml Total of imports of agriculture, forestry and fishing goods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most important characteristic of Swiss-made products\n",
    "\n",
    "After answering our main research questions we would like to find which products are likely to import to Switzerland. To answer this question we would like to train a classifier in order to see which features are the most important features to decide if a product is Swiss made or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve our assumption about date of entering products to the Swiss market\n",
    "\n",
    "Study of the evolution in time of the interest features combined\n",
    "- The k-modes and other machine learning algorithms are expected to be done for the milestone 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
