{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import min\n",
    "from pyspark.sql.functions import to_date, last_day,date_add\n",
    "from datetime import timedelta\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "openfood_file = \"data/en.openfoodfacts.org.products.csv\"\n",
    "cities_file = \"data/countries_cleaning/cities.csv\"\n",
    "countries_file = \"data/countries_cleaning/countries.csv\"\n",
    "\n",
    "output_mapping_just_countries = \"data/countries_cleaning/output/mapping_just_countries.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- manufacturing_places_tags: string (nullable = true)\n",
      " |-- countries_tags: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_main = spark.read.csv(openfood_file, header=True, mode=\"DROPMALFORMED\", sep = '\\t')\n",
    "\n",
    "dataset_main.createOrReplaceTempView(\"data_main\")\n",
    "\n",
    "# Filter required columns\n",
    "p_id_col = \" code, \"\n",
    "geo_tags_cols = \" manufacturing_places_tags, countries_tags \"\n",
    "\n",
    "off_df = spark.sql(\"SELECT\" + p_id_col + geo_tags_cols + \" FROM data_main\")\n",
    "off_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data Size:\n",
      "3(columns) * 709945(rows)\n"
     ]
    }
   ],
   "source": [
    "off_all_size = off_df.count()\n",
    "off_cols_size = len(off_df.columns)\n",
    "print(\"All data Size:\\n\" + str(off_cols_size) + \"(columns) * \" + str(off_all_size) + \"(rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------+--------------+\n",
      "|code|manufacturing_places_tags|countries_tags|\n",
      "+----+-------------------------+--------------+\n",
      "|   0|                   641206|           554|\n",
      "+----+-------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find number of missing data\n",
    "\n",
    "off_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in off_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full GEO information data Size:\n",
      "3(columns) * 68672(rows)\n"
     ]
    }
   ],
   "source": [
    "off_df.createOrReplaceTempView(\"off_df\")\n",
    "\n",
    "sql_filter = \"SELECT * FROM off_df WHERE \\\n",
    "            countries_tags is not NULL AND manufacturing_places_tags is not NULL \"\n",
    "\n",
    "off_p_df = spark.sql(sql_filter)\n",
    "off_p_all_size = off_p_df.count()\n",
    "off_p_cols_size = len(off_p_df.columns)\n",
    "print(\"Full GEO information data Size:\\n\" + str(off_p_cols_size) + \"(columns) * \" + str(off_p_all_size) + \"(rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------------+-----------------+\n",
      "|         code|manufacturing_places_tags|   countries_tags|\n",
      "+-------------+-------------------------+-----------------+\n",
      "|0000000020114|                   france|        en:france|\n",
      "|0000000274722|                   france|        en:france|\n",
      "|0000000290616|          brossard-quebec|        en:canada|\n",
      "|0000000394710|          brossard-quebec|        en:canada|\n",
      "|0000001071894|           united-kingdom|en:united-kingdom|\n",
      "+-------------+-------------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "off_p_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since columns with _tag label have more consistent data, we will use these columns from now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------------+--------------+\n",
      "|         code|manufacturing_places_tags|countries_tags|\n",
      "+-------------+-------------------------+--------------+\n",
      "|0000000020114|                   france|        france|\n",
      "|0000000274722|                   france|        france|\n",
      "|0000000290616|          brossard-quebec|        canada|\n",
      "|0000000394710|          brossard-quebec|        canada|\n",
      "|0000001071894|           united-kingdom|united-kingdom|\n",
      "+-------------+-------------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove \"en:\" occurances before name of each country in coutries_tags\n",
    "off_p_df = off_p_df.withColumn('countries_tags', F.regexp_replace('countries_tags', \"en:\", \"\"))\n",
    "off_p_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>manufacturing_places_tags</th>\n",
       "      <th>countries_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000020114</td>\n",
       "      <td>france</td>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000000274722</td>\n",
       "      <td>france</td>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000000290616</td>\n",
       "      <td>brossard-quebec</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000000394710</td>\n",
       "      <td>brossard-quebec</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000001071894</td>\n",
       "      <td>united-kingdom</td>\n",
       "      <td>united-kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            code manufacturing_places_tags  countries_tags\n",
       "0  0000000020114                    france          france\n",
       "1  0000000274722                    france          france\n",
       "2  0000000290616           brossard-quebec          canada\n",
       "3  0000000394710           brossard-quebec          canada\n",
       "4  0000001071894            united-kingdom  united-kingdom"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_mapping = off_p_df.toPandas()\n",
    "countries_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new database mapping each country to some labels\n",
    "\n",
    "countries_mapping['all_countries'] = countries_mapping.manufacturing_places_tags +\",\" + countries_mapping.countries_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>manufacturing_places_tags</th>\n",
       "      <th>countries_tags</th>\n",
       "      <th>all_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000020114</td>\n",
       "      <td>france</td>\n",
       "      <td>france</td>\n",
       "      <td>france,france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000000274722</td>\n",
       "      <td>france</td>\n",
       "      <td>france</td>\n",
       "      <td>france,france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000000290616</td>\n",
       "      <td>brossard-quebec</td>\n",
       "      <td>canada</td>\n",
       "      <td>brossard-quebec,canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000000394710</td>\n",
       "      <td>brossard-quebec</td>\n",
       "      <td>canada</td>\n",
       "      <td>brossard-quebec,canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000001071894</td>\n",
       "      <td>united-kingdom</td>\n",
       "      <td>united-kingdom</td>\n",
       "      <td>united-kingdom,united-kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            code manufacturing_places_tags  countries_tags  \\\n",
       "0  0000000020114                    france          france   \n",
       "1  0000000274722                    france          france   \n",
       "2  0000000290616           brossard-quebec          canada   \n",
       "3  0000000394710           brossard-quebec          canada   \n",
       "4  0000001071894            united-kingdom  united-kingdom   \n",
       "\n",
       "                   all_countries  \n",
       "0                  france,france  \n",
       "1                  france,france  \n",
       "2         brossard-quebec,canada  \n",
       "3         brossard-quebec,canada  \n",
       "4  united-kingdom,united-kingdom  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             france\n",
       "1             france\n",
       "2             france\n",
       "3             france\n",
       "4    brossard-quebec\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = pd.concat([pd.Series(row['all_countries'].split(','))              \n",
    "                    for _, row in countries_mapping.iterrows()]).reset_index(drop=True)\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192203"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12357\n"
     ]
    }
   ],
   "source": [
    "countries = countries.drop_duplicates().reset_index(drop=True)\n",
    "countries = countries.str.replace(\"-\", \" \") \n",
    "\n",
    "# Remove numbers from name of countries\n",
    "countries = countries.str.replace('\\d+', '')\n",
    "\n",
    "print(len(countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             france\n",
       "1    brossard quebec\n",
       "2             canada\n",
       "3     united kingdom\n",
       "4           brossard\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have extracted all unique values in country_tags and manufacturing_places_tags columns. \n",
    "We have 12357 unique entry.\n",
    "Now we should map each of these entries to a country code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapn_countries will keep the mappings\n",
    "map_countries = pd.DataFrame(columns=['input', 'country_code'])\n",
    "remained_countries = countries.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cleaning_status():\n",
    "    print(\"{0} name of countries have been detected in uncleaned dataset\".format(len(map_countries)))\n",
    "    print(\"{0} name of countries have remained\".format(len(remained_countries)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 name of countries have been detected in uncleaned dataset\n",
      "12357 name of countries have remained\n"
     ]
    }
   ],
   "source": [
    "print_cleaning_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two external databases were used for mapping of country names and city names.\n",
    "https://www.geodatasource.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC_FIPS</th>\n",
       "      <th>COUNTRY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>Aruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AC</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AG</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CC_FIPS          COUNTRY_NAME\n",
       "0      AA                 Aruba\n",
       "1      AC   Antigua and Barbuda\n",
       "2      AE  United Arab Emirates\n",
       "3      AF           Afghanistan\n",
       "4      AG               Algeria"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_countries = pd.read_csv(countries_file, error_bad_lines=False)\n",
    "dataset_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_country(data, country_code):\n",
    "    global map_countries\n",
    "    map_countries = map_countries.append({'input': data, 'country_code': country_code}, ignore_index=True)\n",
    "\n",
    "def find_country(data):\n",
    "    # map data with country code\n",
    "    output = dataset_countries[dataset_countries.CC_FIPS.str.match(data, case=False)]\n",
    "    \n",
    "    if len(data) <=2:\n",
    "        # If length of data is less than 3 and has not been matched with a country code, data is not valid\n",
    "        return 0\n",
    "    \n",
    "    if not len(output):\n",
    "        # map data with name of a country \n",
    "        output = dataset_countries[dataset_countries.COUNTRY_NAME.str.match(data, case=False)]\n",
    "        \n",
    "    if not len(output):\n",
    "        # map data with name of a country \n",
    "        output = dataset_countries[dataset_countries.COUNTRY_NAME.str.contains(data, case=False)]\n",
    "        \n",
    "    if len(output):\n",
    "        return output.iloc[0].CC_FIPS\n",
    "    return 0\n",
    "\n",
    "def assign_country_code(row):\n",
    "    output = find_country(row)\n",
    "    if output:\n",
    "        map_country(row, output)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(remained_countries)):\n",
    "    if assign_country_code(remained_countries[i]):\n",
    "        remained_countries = remained_countries.drop([i])\n",
    "        i -=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776 name of countries have been detected in uncleaned dataset\n",
      "11581 name of countries have remained\n"
     ]
    }
   ],
   "source": [
    "print_cleaning_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find entries which contain name of a country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dataset_countries.iterrows():\n",
    "    # If data contains name of a country before other words\n",
    "    output = remained_countries[remained_countries.str.contains(row.COUNTRY_NAME + \" \", case=False, na=False)]\n",
    "    \n",
    "    if not len(output):\n",
    "        # If data contains name of a country after other words\n",
    "         output = remained_countries[remained_countries.str.contains(\" \" + row.COUNTRY_NAME, case=False, na=False)]   \n",
    "    \n",
    "    for i in range(len(output)):\n",
    "        map_country(output.iloc[i], row.CC_FIPS)\n",
    "        remained_countries = remained_countries.drop(remained_countries[remained_countries == output.iloc[i]].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776 name of countries have been detected in uncleaned dataset\n",
      "11581 name of countries have remained\n"
     ]
    }
   ],
   "source": [
    "print_cleaning_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>en south africa</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>es  gador almeira spain</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>nutriops s l r g s a   m u avda c blancos p   ...</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>alhama de murcia spain</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>valencia spain</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>micarna sa divison volaille rte de l industrie...</td>\n",
       "      <td>SZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>i̇stanbul turkey</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>istanbul turkey</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>en united states</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>virgin islands of the united states</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input country_code\n",
       "766                                    en south africa           SF\n",
       "767                            es  gador almeira spain           SP\n",
       "768  nutriops s l r g s a   m u avda c blancos p   ...           SP\n",
       "769                             alhama de murcia spain           SP\n",
       "770                                     valencia spain           SP\n",
       "771  micarna sa divison volaille rte de l industrie...           SZ\n",
       "772                                   i̇stanbul turkey           TU\n",
       "773                                    istanbul turkey           TU\n",
       "774                                   en united states           US\n",
       "775                virgin islands of the united states           US"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_countries.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 776 detected inputs \n",
    "map_countries.to_csv(output_mapping_just_countries, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using City names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 3404: expected 2 fields, saw 3\\nSkipping line 26344: expected 2 fields, saw 3\\nSkipping line 26424: expected 2 fields, saw 3\\nSkipping line 27358: expected 2 fields, saw 3\\nSkipping line 28220: expected 2 fields, saw 3\\nSkipping line 28221: expected 2 fields, saw 3\\nSkipping line 28382: expected 2 fields, saw 3\\nSkipping line 28734: expected 2 fields, saw 3\\nSkipping line 29051: expected 2 fields, saw 3\\nSkipping line 29056: expected 2 fields, saw 3\\nSkipping line 29128: expected 2 fields, saw 3\\nSkipping line 29183: expected 2 fields, saw 3\\nSkipping line 44241: expected 2 fields, saw 3\\nSkipping line 65686: expected 2 fields, saw 3\\nSkipping line 67481: expected 2 fields, saw 3\\nSkipping line 69168: expected 2 fields, saw 3\\nSkipping line 70683: expected 2 fields, saw 3\\nSkipping line 74874: expected 2 fields, saw 3\\nSkipping line 76715: expected 2 fields, saw 3\\nSkipping line 79939: expected 2 fields, saw 3\\nSkipping line 79940: expected 2 fields, saw 3\\nSkipping line 80623: expected 2 fields, saw 3\\nSkipping line 82309: expected 2 fields, saw 3\\nSkipping line 127006: expected 2 fields, saw 3\\nSkipping line 130729: expected 2 fields, saw 3\\nSkipping line 130914: expected 2 fields, saw 4\\nSkipping line 142973: expected 2 fields, saw 3\\nSkipping line 182618: expected 2 fields, saw 4\\nSkipping line 184575: expected 2 fields, saw 3\\nSkipping line 184576: expected 2 fields, saw 3\\nSkipping line 199267: expected 2 fields, saw 3\\nSkipping line 199408: expected 2 fields, saw 3\\nSkipping line 224734: expected 2 fields, saw 4\\nSkipping line 231451: expected 2 fields, saw 3\\nSkipping line 244922: expected 2 fields, saw 3\\nSkipping line 245900: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 285548: expected 2 fields, saw 3\\nSkipping line 285549: expected 2 fields, saw 3\\nSkipping line 286610: expected 2 fields, saw 3\\nSkipping line 287835: expected 2 fields, saw 3\\nSkipping line 293191: expected 2 fields, saw 3\\nSkipping line 293482: expected 2 fields, saw 3\\nSkipping line 293585: expected 2 fields, saw 3\\nSkipping line 294691: expected 2 fields, saw 3\\nSkipping line 294692: expected 2 fields, saw 3\\nSkipping line 294693: expected 2 fields, saw 3\\nSkipping line 294694: expected 2 fields, saw 3\\nSkipping line 294695: expected 2 fields, saw 3\\nSkipping line 296025: expected 2 fields, saw 3\\nSkipping line 296420: expected 2 fields, saw 3\\nSkipping line 310653: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 581743: expected 2 fields, saw 3\\nSkipping line 608769: expected 2 fields, saw 3\\nSkipping line 616594: expected 2 fields, saw 3\\nSkipping line 618168: expected 2 fields, saw 3\\nSkipping line 618708: expected 2 fields, saw 3\\nSkipping line 618982: expected 2 fields, saw 3\\nSkipping line 619115: expected 2 fields, saw 3\\nSkipping line 647292: expected 2 fields, saw 3\\nSkipping line 651276: expected 2 fields, saw 3\\nSkipping line 680722: expected 2 fields, saw 3\\nSkipping line 681369: expected 2 fields, saw 3\\nSkipping line 690922: expected 2 fields, saw 3\\nSkipping line 724723: expected 2 fields, saw 3\\nSkipping line 724737: expected 2 fields, saw 3\\nSkipping line 742794: expected 2 fields, saw 3\\nSkipping line 744603: expected 2 fields, saw 3\\nSkipping line 750866: expected 2 fields, saw 3\\nSkipping line 756746: expected 2 fields, saw 3\\nSkipping line 759809: expected 2 fields, saw 3\\nSkipping line 761603: expected 2 fields, saw 3\\nSkipping line 770450: expected 2 fields, saw 3\\nSkipping line 782364: expected 2 fields, saw 3\\nSkipping line 786055: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 787550: expected 2 fields, saw 3\\nSkipping line 787961: expected 2 fields, saw 3\\nSkipping line 790795: expected 2 fields, saw 3\\nSkipping line 793123: expected 2 fields, saw 3\\nSkipping line 794815: expected 2 fields, saw 3\\nSkipping line 797185: expected 2 fields, saw 3\\nSkipping line 800632: expected 2 fields, saw 3\\nSkipping line 801075: expected 2 fields, saw 3\\nSkipping line 801244: expected 2 fields, saw 3\\nSkipping line 804668: expected 2 fields, saw 3\\nSkipping line 805102: expected 2 fields, saw 3\\nSkipping line 805274: expected 2 fields, saw 3\\nSkipping line 805578: expected 2 fields, saw 3\\nSkipping line 805730: expected 2 fields, saw 3\\nSkipping line 805854: expected 2 fields, saw 3\\nSkipping line 805877: expected 2 fields, saw 3\\nSkipping line 806059: expected 2 fields, saw 3\\nSkipping line 806719: expected 2 fields, saw 3\\nSkipping line 807285: expected 2 fields, saw 3\\nSkipping line 807510: expected 2 fields, saw 3\\nSkipping line 808716: expected 2 fields, saw 3\\nSkipping line 809098: expected 2 fields, saw 3\\nSkipping line 809130: expected 2 fields, saw 3\\nSkipping line 809207: expected 2 fields, saw 3\\nSkipping line 809312: expected 2 fields, saw 3\\nSkipping line 809438: expected 2 fields, saw 3\\nSkipping line 809783: expected 2 fields, saw 3\\nSkipping line 810089: expected 2 fields, saw 3\\nSkipping line 810143: expected 2 fields, saw 3\\nSkipping line 810348: expected 2 fields, saw 3\\nSkipping line 811096: expected 2 fields, saw 3\\nSkipping line 813292: expected 2 fields, saw 3\\nSkipping line 813431: expected 2 fields, saw 3\\nSkipping line 818814: expected 2 fields, saw 3\\nSkipping line 820481: expected 2 fields, saw 3\\nSkipping line 822900: expected 2 fields, saw 3\\nSkipping line 823960: expected 2 fields, saw 6\\nSkipping line 824512: expected 2 fields, saw 3\\nSkipping line 830063: expected 2 fields, saw 3\\nSkipping line 831885: expected 2 fields, saw 3\\nSkipping line 833508: expected 2 fields, saw 3\\nSkipping line 834320: expected 2 fields, saw 3\\nSkipping line 839789: expected 2 fields, saw 3\\nSkipping line 840319: expected 2 fields, saw 3\\nSkipping line 842961: expected 2 fields, saw 3\\nSkipping line 843014: expected 2 fields, saw 3\\nSkipping line 851038: expected 2 fields, saw 3\\nSkipping line 853405: expected 2 fields, saw 3\\nSkipping line 853523: expected 2 fields, saw 3\\nSkipping line 853553: expected 2 fields, saw 3\\nSkipping line 862961: expected 2 fields, saw 3\\nSkipping line 892033: expected 2 fields, saw 3\\nSkipping line 909729: expected 2 fields, saw 3\\nSkipping line 911548: expected 2 fields, saw 3\\nSkipping line 943710: expected 2 fields, saw 3\\nSkipping line 989559: expected 2 fields, saw 3\\nSkipping line 1000457: expected 2 fields, saw 3\\nSkipping line 1001420: expected 2 fields, saw 3\\nSkipping line 1006089: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 1081899: expected 2 fields, saw 3\\nSkipping line 1081900: expected 2 fields, saw 3\\nSkipping line 1090060: expected 2 fields, saw 3\\nSkipping line 1110265: expected 2 fields, saw 4\\nSkipping line 1141916: expected 2 fields, saw 3\\nSkipping line 1153206: expected 2 fields, saw 4\\nSkipping line 1189334: expected 2 fields, saw 3\\nSkipping line 1197858: expected 2 fields, saw 4\\nSkipping line 1213314: expected 2 fields, saw 3\\nSkipping line 1229072: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 1336268: expected 2 fields, saw 3\\nSkipping line 1396828: expected 2 fields, saw 3\\nSkipping line 1415770: expected 2 fields, saw 3\\nSkipping line 1488395: expected 2 fields, saw 4\\nSkipping line 1519503: expected 2 fields, saw 3\\nSkipping line 1547314: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 1585093: expected 2 fields, saw 3\\nSkipping line 1591428: expected 2 fields, saw 3\\nSkipping line 1591581: expected 2 fields, saw 4\\nSkipping line 1592422: expected 2 fields, saw 3\\nSkipping line 1592464: expected 2 fields, saw 3\\nSkipping line 1592738: expected 2 fields, saw 3\\nSkipping line 1719600: expected 2 fields, saw 3\\nSkipping line 1772972: expected 2 fields, saw 3\\nSkipping line 1818552: expected 2 fields, saw 3\\nSkipping line 1823150: expected 2 fields, saw 3\\nSkipping line 1827006: expected 2 fields, saw 3\\nSkipping line 1827865: expected 2 fields, saw 4\\nSkipping line 1830014: expected 2 fields, saw 3\\nSkipping line 1833340: expected 2 fields, saw 3\\nSkipping line 1833367: expected 2 fields, saw 3\\nSkipping line 1833958: expected 2 fields, saw 3\\nSkipping line 1833959: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 1838612: expected 2 fields, saw 3\\nSkipping line 1839264: expected 2 fields, saw 3\\nSkipping line 1841720: expected 2 fields, saw 4\\nSkipping line 1844851: expected 2 fields, saw 3\\nSkipping line 1848555: expected 2 fields, saw 3\\nSkipping line 1860210: expected 2 fields, saw 3\\nSkipping line 1863071: expected 2 fields, saw 3\\nSkipping line 1864414: expected 2 fields, saw 3\\nSkipping line 1864764: expected 2 fields, saw 3\\nSkipping line 1865233: expected 2 fields, saw 3\\nSkipping line 1866074: expected 2 fields, saw 3\\nSkipping line 1872474: expected 2 fields, saw 3\\nSkipping line 1884963: expected 2 fields, saw 3\\nSkipping line 1888468: expected 2 fields, saw 3\\nSkipping line 1889535: expected 2 fields, saw 3\\nSkipping line 1889893: expected 2 fields, saw 3\\nSkipping line 1900938: expected 2 fields, saw 3\\nSkipping line 1912074: expected 2 fields, saw 3\\nSkipping line 1913046: expected 2 fields, saw 3\\nSkipping line 1934296: expected 2 fields, saw 3\\nSkipping line 1940706: expected 2 fields, saw 3\\nSkipping line 1947355: expected 2 fields, saw 5\\nSkipping line 1950807: expected 2 fields, saw 3\\nSkipping line 1951236: expected 2 fields, saw 3\\nSkipping line 2027405: expected 2 fields, saw 3\\nSkipping line 2027406: expected 2 fields, saw 3\\nSkipping line 2033288: expected 2 fields, saw 3\\nSkipping line 2033361: expected 2 fields, saw 3\\nSkipping line 2033490: expected 2 fields, saw 3\\nSkipping line 2033975: expected 2 fields, saw 3\\nSkipping line 2034360: expected 2 fields, saw 3\\nSkipping line 2034562: expected 2 fields, saw 3\\nSkipping line 2034772: expected 2 fields, saw 3\\nSkipping line 2034840: expected 2 fields, saw 3\\nSkipping line 2035021: expected 2 fields, saw 3\\nSkipping line 2035026: expected 2 fields, saw 3\\nSkipping line 2035247: expected 2 fields, saw 3\\nSkipping line 2035353: expected 2 fields, saw 3\\nSkipping line 2035473: expected 2 fields, saw 3\\nSkipping line 2035698: expected 2 fields, saw 3\\nSkipping line 2035779: expected 2 fields, saw 3\\nSkipping line 2035902: expected 2 fields, saw 3\\nSkipping line 2036025: expected 2 fields, saw 3\\nSkipping line 2036048: expected 2 fields, saw 3\\nSkipping line 2036057: expected 2 fields, saw 3\\nSkipping line 2036058: expected 2 fields, saw 3\\nSkipping line 2036215: expected 2 fields, saw 3\\nSkipping line 2036380: expected 2 fields, saw 3\\nSkipping line 2036408: expected 2 fields, saw 3\\nSkipping line 2036905: expected 2 fields, saw 3\\nSkipping line 2037109: expected 2 fields, saw 3\\nSkipping line 2037422: expected 2 fields, saw 3\\nSkipping line 2037423: expected 2 fields, saw 3\\nSkipping line 2037492: expected 2 fields, saw 3\\nSkipping line 2037728: expected 2 fields, saw 3\\nSkipping line 2037738: expected 2 fields, saw 3\\nSkipping line 2038156: expected 2 fields, saw 3\\nSkipping line 2038544: expected 2 fields, saw 3\\nSkipping line 2038545: expected 2 fields, saw 3\\nSkipping line 2039132: expected 2 fields, saw 3\\nSkipping line 2039133: expected 2 fields, saw 3\\nSkipping line 2039239: expected 2 fields, saw 3\\nSkipping line 2039286: expected 2 fields, saw 3\\nSkipping line 2039661: expected 2 fields, saw 3\\nSkipping line 2040143: expected 2 fields, saw 3\\nSkipping line 2040193: expected 2 fields, saw 3\\nSkipping line 2040194: expected 2 fields, saw 3\\nSkipping line 2040399: expected 2 fields, saw 3\\nSkipping line 2040758: expected 2 fields, saw 3\\nSkipping line 2041044: expected 2 fields, saw 3\\nSkipping line 2041102: expected 2 fields, saw 3\\nSkipping line 2041420: expected 2 fields, saw 3\\nSkipping line 2042323: expected 2 fields, saw 3\\nSkipping line 2042897: expected 2 fields, saw 3\\nSkipping line 2043249: expected 2 fields, saw 3\\nSkipping line 2043250: expected 2 fields, saw 3\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2120457: expected 2 fields, saw 3\\nSkipping line 2143498: expected 2 fields, saw 3\\nSkipping line 2152938: expected 2 fields, saw 3\\nSkipping line 2152939: expected 2 fields, saw 3\\nSkipping line 2152940: expected 2 fields, saw 3\\nSkipping line 2152942: expected 2 fields, saw 3\\nSkipping line 2152943: expected 2 fields, saw 3\\nSkipping line 2152944: expected 2 fields, saw 3\\nSkipping line 2152945: expected 2 fields, saw 3\\nSkipping line 2156181: expected 2 fields, saw 3\\nSkipping line 2156939: expected 2 fields, saw 3\\nSkipping line 2157870: expected 2 fields, saw 3\\nSkipping line 2159388: expected 2 fields, saw 5\\nSkipping line 2159627: expected 2 fields, saw 3\\nSkipping line 2160286: expected 2 fields, saw 3\\nSkipping line 2164938: expected 2 fields, saw 3\\nSkipping line 2165243: expected 2 fields, saw 3\\nSkipping line 2167702: expected 2 fields, saw 3\\nSkipping line 2171276: expected 2 fields, saw 3\\nSkipping line 2172138: expected 2 fields, saw 3\\nSkipping line 2176160: expected 2 fields, saw 3\\nSkipping line 2268861: expected 2 fields, saw 5\\nSkipping line 2282493: expected 2 fields, saw 3\\nSkipping line 2288673: expected 2 fields, saw 3\\nSkipping line 2295780: expected 2 fields, saw 3\\nSkipping line 2304585: expected 2 fields, saw 3\\nSkipping line 2335094: expected 2 fields, saw 3\\nSkipping line 2341826: expected 2 fields, saw 3\\nSkipping line 2341827: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 2388360: expected 2 fields, saw 3\\nSkipping line 2415305: expected 2 fields, saw 3\\nSkipping line 2435121: expected 2 fields, saw 3\\nSkipping line 2468541: expected 2 fields, saw 3\\nSkipping line 2487174: expected 2 fields, saw 3\\nSkipping line 2498367: expected 2 fields, saw 3\\nSkipping line 2503894: expected 2 fields, saw 3\\nSkipping line 2504687: expected 2 fields, saw 3\\nSkipping line 2506781: expected 2 fields, saw 3\\nSkipping line 2510013: expected 2 fields, saw 3\\nSkipping line 2514107: expected 2 fields, saw 3\\nSkipping line 2515979: expected 2 fields, saw 3\\nSkipping line 2545297: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 2634015: expected 2 fields, saw 3\\nSkipping line 2660539: expected 2 fields, saw 3\\nSkipping line 2679358: expected 2 fields, saw 3\\nSkipping line 2684685: expected 2 fields, saw 3\\nSkipping line 2697005: expected 2 fields, saw 4\\nSkipping line 2697793: expected 2 fields, saw 3\\nSkipping line 2697986: expected 2 fields, saw 3\\nSkipping line 2705436: expected 2 fields, saw 3\\nSkipping line 2705640: expected 2 fields, saw 3\\nSkipping line 2708810: expected 2 fields, saw 3\\nSkipping line 2709043: expected 2 fields, saw 3\\nSkipping line 2709202: expected 2 fields, saw 3\\nSkipping line 2711749: expected 2 fields, saw 3\\nSkipping line 2711750: expected 2 fields, saw 3\\nSkipping line 2712150: expected 2 fields, saw 3\\nSkipping line 2714609: expected 2 fields, saw 3\\nSkipping line 2715588: expected 2 fields, saw 3\\nSkipping line 2716898: expected 2 fields, saw 3\\nSkipping line 2719545: expected 2 fields, saw 3\\nSkipping line 2720795: expected 2 fields, saw 3\\nSkipping line 2720851: expected 2 fields, saw 3\\nSkipping line 2721735: expected 2 fields, saw 3\\nSkipping line 2725910: expected 2 fields, saw 3\\nSkipping line 2727215: expected 2 fields, saw 3\\nSkipping line 2729077: expected 2 fields, saw 3\\nSkipping line 2732227: expected 2 fields, saw 3\\nSkipping line 2734471: expected 2 fields, saw 3\\nSkipping line 2738016: expected 2 fields, saw 3\\nSkipping line 2738829: expected 2 fields, saw 3\\nSkipping line 2739542: expected 2 fields, saw 3\\nSkipping line 2743283: expected 2 fields, saw 3\\nSkipping line 2743581: expected 2 fields, saw 3\\nSkipping line 2745793: expected 2 fields, saw 3\\nSkipping line 2752319: expected 2 fields, saw 3\\nSkipping line 2753422: expected 2 fields, saw 3\\nSkipping line 2753613: expected 2 fields, saw 3\\nSkipping line 2756664: expected 2 fields, saw 3\\nSkipping line 2759537: expected 2 fields, saw 3\\nSkipping line 2760911: expected 2 fields, saw 3\\nSkipping line 2761731: expected 2 fields, saw 5\\nSkipping line 2762398: expected 2 fields, saw 3\\nSkipping line 2763253: expected 2 fields, saw 3\\nSkipping line 2766619: expected 2 fields, saw 3\\nSkipping line 2767734: expected 2 fields, saw 3\\nSkipping line 2768084: expected 2 fields, saw 4\\nSkipping line 2779423: expected 2 fields, saw 3\\nSkipping line 2779835: expected 2 fields, saw 3\\nSkipping line 2782160: expected 2 fields, saw 3\\nSkipping line 2783161: expected 2 fields, saw 3\\nSkipping line 2784577: expected 2 fields, saw 3\\nSkipping line 2785424: expected 2 fields, saw 3\\nSkipping line 2788375: expected 2 fields, saw 3\\nSkipping line 2788772: expected 2 fields, saw 3\\nSkipping line 2792282: expected 2 fields, saw 3\\nSkipping line 2794053: expected 2 fields, saw 5\\nSkipping line 2794332: expected 2 fields, saw 3\\nSkipping line 2795501: expected 2 fields, saw 3\\nSkipping line 2796837: expected 2 fields, saw 3\\nSkipping line 2796838: expected 2 fields, saw 3\\nSkipping line 2796839: expected 2 fields, saw 3\\nSkipping line 2796841: expected 2 fields, saw 3\\nSkipping line 2796842: expected 2 fields, saw 3\\nSkipping line 2799672: expected 2 fields, saw 3\\nSkipping line 2800423: expected 2 fields, saw 3\\nSkipping line 2805382: expected 2 fields, saw 4\\nSkipping line 2844127: expected 2 fields, saw 3\\nSkipping line 2844128: expected 2 fields, saw 3\\nSkipping line 2854627: expected 2 fields, saw 3\\n'\n",
      "b'Skipping line 2885091: expected 2 fields, saw 3\\n'\n"
     ]
    }
   ],
   "source": [
    "# Find name of cities and replace with country code (Here some bias may happen, some cities have similar name)\n",
    "\n",
    "dataset_cities = pd.read_csv(cities_file, sep=',', error_bad_lines=False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC_FIPS</th>\n",
       "      <th>FULL_NAME_ND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AN</td>\n",
       "      <td>Aixas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AN</td>\n",
       "      <td>Aixirivall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AN</td>\n",
       "      <td>Aixovall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AN</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AN</td>\n",
       "      <td>Ansalonga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CC_FIPS      FULL_NAME_ND\n",
       "0      AN             Aixas\n",
       "1      AN        Aixirivall\n",
       "2      AN          Aixovall\n",
       "3      AN  Andorra la Vella\n",
       "4      AN         Ansalonga"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cities in the external dataset: 2915558\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of cities in the external dataset: {0}\".format(len(dataset_cities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remained_countries_backup = remained_countries.copy()\n",
    "map_countries_backup = map_countries.copy()\n",
    "len(map_countries_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776 name of countries have been detected in uncleaned dataset\n",
      "11581 name of countries have remained\n"
     ]
    }
   ],
   "source": [
    "remained_countries = remained_countries_backup.copy()\n",
    "map_countries = map_countries_backup.copy()\n",
    "print_cleaning_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_city(data):\n",
    "    \n",
    "    if len(data) <=2:\n",
    "        # If length of data is less than 3 data is not valid\n",
    "        return 0\n",
    "    \n",
    "    # map data with name of a city \n",
    "    output = dataset_cities[dataset_cities.FULL_NAME_ND.str.match(data, case=False, na=False)]\n",
    "        \n",
    "    if not len(output):\n",
    "        # map data if it contains name of a city \n",
    "        output = dataset_cities[dataset_cities.FULL_NAME_ND.str.contains(\" \" + data + \"|\"+ data + \" \", case=False, regex=True, na=False)]\n",
    "\n",
    "    if len(output):\n",
    "            print(data + \"-->\" +output.iloc[0].CC_FIPS)\n",
    "            return output.iloc[0].CC_FIPS\n",
    "    return 0\n",
    "\n",
    "def assign_country_code_using_city(row):\n",
    "    output = find_city(row)\n",
    "    if output:\n",
    "        map_country(row, output)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = 0\n",
    "interval = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cameroun-->GB\n",
      "rully-->FR\n",
      "meloisey-->FR\n",
      "chagny-->FR\n",
      "ny -->DA\n",
      "ankara-->GG\n",
      "montmorin-->FR\n",
      "langenburg-->CA\n",
      "irland-->BL\n",
      "850\n",
      "oliveira de azemeis-->PO\n",
      "mesnay-->FR\n",
      "grasse-->AU\n",
      "voiron-->FR\n",
      "augsburg-->CA\n",
      "franca-->BR\n",
      "olhao-->PO\n",
      "selonnet-->FR\n",
      "var-->AF\n",
      "sagy-->FR\n",
      "camembert-->FR\n",
      "rennes-->GM\n",
      "clisson-->FR\n",
      "asturias-->AR\n",
      "tailandia-->BR\n",
      "nimes-->FR\n",
      "world-->AS\n",
      "oosterhout-->NL\n",
      "karaman-->AJ\n",
      "dudullu-->TU\n",
      "umraniye-->TU\n",
      "idaho falls-->US\n",
      "900\n",
      "neu isenburg-->GM\n",
      " paris-->KR\n",
      "jandu-->BR\n",
      "lyon-->AC\n",
      "corbas-->FR\n",
      "shandong-->CH\n",
      "monastir-->BU\n",
      "valladolid-->CO\n",
      "draguignan-->FR\n",
      "mantilly-->FR\n",
      "orne-->AU\n",
      "zaragoza-->CO\n",
      "bondoufle-->FR\n",
      "angers-->AM\n",
      "douarnenez-->FR\n",
      "maslives-->FR\n",
      "estillac-->FR\n",
      "chamboulive-->FR\n",
      "virolle-->FR\n",
      "sayan-->BG\n",
      "nantes-->BR\n",
      "le hezo-->FR\n",
      "vignoc-->FR\n",
      "950\n",
      "mayenne-->FR\n",
      "urecheni-->RO\n",
      "cuneo-->IT\n",
      "limete-->NP\n",
      "kinshasa-->CG\n",
      "trieste-->CO\n",
      "ploneis-->FR\n",
      "huningue-->FR\n",
      "jaxu-->FR\n",
      "1000\n",
      "argelier-->FR\n",
      "languedoc-->CA\n",
      "longeves-->FR\n",
      "marans-->BE\n",
      "bagard-->BG\n",
      "rhone-->BE\n",
      "crolles-->FR\n",
      "lembeke-->BE\n",
      "toulouse-->FR\n",
      "avoudrey-->FR\n",
      "colima-->CI\n",
      "limoges-->BE\n",
      "leclerc-->CA\n",
      "peine-->CI\n",
      "niedersachsen-->WA\n",
      "via madonna -->IT\n",
      "lallio-->IT\n",
      "eksjo-->SW\n",
      "breme-->AS\n",
      "heilbronn-->GM\n",
      "1050\n",
      "aurich-->GM\n",
      "golssen-->GM\n",
      "bourges-->FR\n",
      " foggia-->IT\n",
      "trilles-->NO\n",
      "maureilhan-->FR\n",
      "kentucky-->AS\n",
      "alemanha-->BR\n",
      "valle lomellina-->IT\n",
      "landshut-->AU\n",
      "porto-->AL\n",
      "wiesbaden-->GM\n",
      "blanquefort-->FR\n",
      "le bignon-->FR\n",
      "saint hippolyte-->CA\n",
      "1100\n",
      "parma-->AF\n",
      "vienne-->FR\n",
      "granarolo-->IT\n",
      "romans-->SZ\n",
      "lons-->AU\n",
      "osuna-->SP\n",
      "alicante-->CO\n",
      "paises bajos-->EC\n",
      "gador-->SP\n",
      "arroyo de la encomienda-->SP\n",
      "1150\n",
      "espanha-->BR\n",
      "aguilar de campoo-->SP\n",
      "brenes-->SP\n",
      "sevilla-->CO\n",
      "spanje-->BE\n",
      "zeven-->BE\n",
      "villalonga-->AR\n",
      "chailly-->SZ\n",
      "lauterach-->AU\n",
      "bermeo-->SP\n",
      "moers-->AU\n",
      "neckarsulm-->GM\n",
      "arguedas-->SP\n",
      "craon-->FR\n",
      "1200\n",
      "meeder-->GM\n",
      "cham-->AF\n",
      "nahe-->CH\n",
      "borgo vercelli-->IT\n",
      "piamonte-->AR\n",
      "catalunya-->PE\n",
      "nortrup-->GM\n",
      "satu mare-->RO\n",
      "graz-->AL\n",
      "simbach am inn-->GM\n",
      "lowicz-->PL\n",
      "elsdorf-->GM\n",
      "1250\n",
      " ac-->MO\n",
      "papendrecht-->NL\n",
      "crailsheim-->GM\n",
      "carquefou-->FR\n",
      "riedberg-->AU\n",
      "fao -->TH\n",
      "fao -->TH\n",
      "bickenbach-->GM\n",
      "leppersdorf-->AU\n",
      "rodez-->SP\n",
      "breuberg-->GM\n",
      "1300\n",
      "ossona-->IT\n",
      "auch-->AO\n",
      "milagro-->AR\n",
      "jenlain-->FR\n",
      "gronau-->GM\n",
      "foggia-->IT\n",
      "montpellier-->CA\n",
      "sourribes-->FR\n",
      "huelva-->SP\n",
      "montelimar-->CO\n",
      "nosibe-->MA\n",
      "garrel-->GM\n",
      "villafranca del bierzo-->SP\n",
      "campohermoso-->CO\n",
      "nijar-->SP\n",
      "1350\n",
      "almeria-->BR\n",
      "la murada-->SP\n",
      "bulgneville-->FR\n",
      "estubeny-->SP\n",
      "borox-->SP\n",
      "aguilas-->CO\n",
      "vicar-->SP\n",
      "terrea-->MX\n",
      "oliva-->AR\n",
      "aube-->AU\n",
      "montauban-->CA\n",
      "bekkevoort-->BE\n",
      "el ejido-->CO\n",
      "sanchonuno-->SP\n",
      "schwarzenfeld-->GM\n",
      "fraga-->AR\n",
      "beindersheim-->GM\n",
      "raismes-->FR\n",
      "alaquas-->SP\n",
      "reino unido-->BR\n",
      "importador-->MX\n",
      "calahorra-->CO\n",
      "luxemburg-->BR\n",
      "bad wimpfen-->GM\n",
      "1400\n",
      "radeberg-->GM\n",
      "don benito-->SP\n",
      "douai-->AG\n",
      "verson-->FR\n",
      "girona-->SP\n",
      "auchan-->IN\n",
      "velizy-->FR\n",
      "petite foret-->FR\n",
      "olivet-->CA\n",
      "benifaio-->SP\n",
      "sao miguel-->AO\n",
      "ponta delgada-->PO\n",
      "acores-->BR\n",
      "pilar de la horadada-->SP\n",
      "schweiz-->AU\n",
      "ribeira grande-->CV\n",
      "essen-->AU\n",
      "frankfurt am main-->GM\n",
      "1450\n",
      "bourgbarre-->FR\n",
      "alginet-->SP\n",
      "maromme-->FR\n",
      "seevetal-->GM\n",
      "allier-->BE\n",
      "fontanilles-->SP\n",
      "errenteria-->SP\n",
      "rietberg-->GM\n",
      "tarragona-->AR\n",
      "boisgervilly-->FR\n",
      "santa eulalia-->CO\n",
      "belgie-->BE\n",
      "turcia-->SP\n",
      "dissen-->GM\n",
      "1500\n",
      "kervignac-->FR\n",
      "tudela-->BL\n",
      "herford-->GM\n",
      "reus-->SZ\n",
      "lapalisse-->FR\n",
      "losar de la vera-->SP\n",
      "pelussin-->FR\n",
      "paterna-->AR\n",
      "ramales de la victoria-->SP\n",
      "cantabria-->CU\n",
      "turquia-->BL\n",
      "el palmar-->AR\n",
      "issenheim-->FR\n",
      "arcens-->FR\n",
      "rovaniemi-->FI\n",
      "miribel-->FR\n",
      "beneixama-->SP\n",
      "via nazionale -->IT\n",
      "mollerussa-->SP\n",
      "jirny-->EZ\n",
      "1550\n",
      "lenteji-->MX\n",
      "bayern-->GM\n",
      "termens-->SP\n",
      "lessay-->FR\n",
      "madras-->AF\n",
      "daroca-->SP\n",
      "bracal-->AS\n",
      "carmoes-->PO\n",
      "torres vedras-->PO\n",
      "voves-->FR\n",
      "mesandans-->FR\n",
      "lodosa-->SP\n",
      "caceres-->BR\n",
      "palencia-->CO\n",
      "villamuriel de cerrato-->SP\n",
      "priego de cordoba-->SP\n",
      "bruhl-->AU\n",
      "orbec-->FR\n",
      "1600\n",
      "montbazin-->FR\n",
      "saint malo-->US\n",
      "marinha grande-->PO\n",
      "mutxamel-->SP\n",
      "creuse-->FR\n",
      "cuellar-->BL\n",
      "alfaro-->CS\n",
      "ribadumia-->SP\n",
      "cortes-->BL\n",
      "burgos-->BL\n",
      "bavegem-->BE\n",
      "chaponost-->FR\n",
      "plelo-->FR\n",
      "aubagne-->FR\n",
      "polska-->BU\n",
      "soliera-->IT\n",
      "verden-->BE\n",
      "folschviller-->FR\n",
      "dipa-->AF\n",
      "1650\n",
      "saint jean-->GB\n",
      "lamballe-->EC\n",
      "britain-->CA\n",
      "llantrisant-->UK\n",
      "wien-->AU\n",
      "vac-->AM\n",
      "burgdorf-->SZ\n",
      "almere-->NL\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-8f9f289d86a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0massign_country_code_using_city\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremained_countries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mremained_countries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremained_countries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m-=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-be73814555fe>\u001b[0m in \u001b[0;36massign_country_code_using_city\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0massign_country_code_using_city\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_city\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmap_country\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-be73814555fe>\u001b[0m in \u001b[0;36mfind_city\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# map data if it contains name of a city\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_cities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_cities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFULL_NAME_ND\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"|\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mcontains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m         result = str_contains(self._data, pat, case=case, flags=flags, na=na,\n\u001b[0;32m-> 2417\u001b[0;31m                               regex=regex)\n\u001b[0m\u001b[1;32m   2418\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_contains\u001b[0;34m(arr, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0muppered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muppered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[0;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# should really _check_ for NA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_map\u001b[0;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    392\u001b[0m                           stacklevel=3)\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "remained_countries = remained_countries.reset_index(drop=True)\n",
    "\n",
    "if len(remained_countries) < interval:\n",
    "    interval = len(remained_countries)\n",
    "for i in range(seen, seen + interval):\n",
    "    if i%50 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    if assign_country_code_using_city(remained_countries[i]):\n",
    "        remained_countries = remained_countries.drop([i])\n",
    "        i -=1\n",
    "        seen = i\n",
    "print(seen)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1674"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>ribadumia</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>cortes</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>burgos</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>bavegem</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>chaponost</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>plelo</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>aubagne</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>polska</td>\n",
       "      <td>BU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>soliera</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>verden</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>folschviller</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>dipa</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>saint jean</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>lamballe</td>\n",
       "      <td>EC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>britain</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>llantrisant</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>wien</td>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>vac</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>burgdorf</td>\n",
       "      <td>SZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>almere</td>\n",
       "      <td>NL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             input country_code\n",
       "1411     ribadumia           SP\n",
       "1412        cortes           BL\n",
       "1413        burgos           BL\n",
       "1414       bavegem           BE\n",
       "1415     chaponost           FR\n",
       "1416         plelo           FR\n",
       "1417       aubagne           FR\n",
       "1418        polska           BU\n",
       "1419       soliera           IT\n",
       "1420        verden           BE\n",
       "1421  folschviller           FR\n",
       "1422          dipa           AF\n",
       "1423    saint jean           GB\n",
       "1424      lamballe           EC\n",
       "1425       britain           CA\n",
       "1426   llantrisant           UK\n",
       "1427          wien           AU\n",
       "1428           vac           AM\n",
       "1429      burgdorf           SZ\n",
       "1430        almere           NL"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_countries.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1431 name of countries have been detected in uncleaned dataset\n",
      "10926 name of countries have remained\n"
     ]
    }
   ],
   "source": [
    "print_cleaning_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2319 locations were matched with city names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "629 locations were matched with city names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using City name (contain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(dataset_cities)):\n",
    "    output = countries[countries.str.contains(str(dataset_cities.iloc[j].City) + \" \", case=False, na=False)]\n",
    "    for i in range(len(output)):\n",
    "        map_country(output.iloc[i], dataset_cities.iloc[j].Country)\n",
    "        countries = countries.drop(countries[countries == output.iloc[i]].index[0])\n",
    "        \n",
    "    output = countries[countries.str.contains(\" \" + str(dataset_cities.iloc[j].City), case=False, na=False)]\n",
    "    for i in range(len(output)):\n",
    "        map_country(output.iloc[i], dataset_cities.iloc[j].Country)\n",
    "        countries = countries.drop(countries[countries == output.iloc[i]].index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5,326 name of countries contain name of one city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318 strings remained\n",
      "7151 strings mapped to a country\n"
     ]
    }
   ],
   "source": [
    "print(\"{0} strings remained\\n{1} strings mapped to a country\".format(len(countries), len(map_countries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In continue:\n",
    "\n",
    "- Evaluate the country detection algorithm by manual checking of a sample of 100 entries\n",
    "- Compute Edit distance for ~1k remained countries\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# countries with occurance more than 195 in the Europe sold data was mapped manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
